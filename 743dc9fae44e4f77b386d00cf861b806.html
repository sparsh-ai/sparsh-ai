<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <!-- Chrome, Firefox OS and Opera Status Bar Color -->
  <meta name="theme-color" content="#FFFFFF">
  <meta property="og:title" content="Pose Estimation">
    <meta property="og:type" content="blog">
  <title>Pose Estimation</title>
  <!-- Favicon -->
    <link rel="shortcut icon" href="üìù">
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
  <link rel="stylesheet" type="text/css"
    href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
  <link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
  <link rel="stylesheet" type="text/css" href="css/notablog.css">
  <link rel="stylesheet" type="text/css" href="css/theme.css">
  <style>
    :root {
      font-size: 18px;
    }

    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
    <a href="index.html">
      <div class="Navbar__Btn"><span>üìù</span> <span>Home</span></div>
    </a>
                                                                                                                                                                                                                                    <span class="Navbar__Delim">&centerdot;</span>
    <a href="extras.html">
      <div class="Navbar__Btn"><span>üìë</span> <span>Extras</span></div>
    </a>
                <span class="Navbar__Delim">&centerdot;</span>
    <a href="aboutme.html">
      <div class="Navbar__Btn"><span>üì®</span> <span>About Me</span></div>
    </a>
          </nav>
  <header class="Header">
          <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
        <h1 class="Header__Title">Pose Estimation</h1>
            <div class="DateTagBar">
                <span class="DateTagBar__Item DateTagBar__Date">Posted on Sun, Jan 3, 2021</span>
                            </div>
          </header>
      <article id="https://www.notion.so/743dc9fae44e4f77b386d00cf861b806" class="PageRoot PageRoot--FullWidth"><div id="https://www.notion.so/ce2e4a1e7f4f4ac7924b054648f1fe27" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F4dca59d3-4ce3-4149-860a-43d6e612348b%2FSlide52.png?width=960&amp;table=block&amp;id=ce2e4a1e-7f4f-4ac7-924b-054648f1fe27"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F4dca59d3-4ce3-4149-860a-43d6e612348b%2FSlide52.png?width=960&amp;table=block&amp;id=ce2e4a1e-7f4f-4ac7-924b-054648f1fe27" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/781b2683a0b047f0902600dd3f8612b5" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F4d7e60a8-0fa6-4801-94e2-e48dc42e668f%2Fimg.png?width=960&amp;table=block&amp;id=781b2683-a0b0-47f0-9026-00dd3f8612b5"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F4d7e60a8-0fa6-4801-94e2-e48dc42e668f%2Fimg.png?width=960&amp;table=block&amp;id=781b2683-a0b0-47f0-9026-00dd3f8612b5" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/07c50c3593a6448f9d3d699068f69124" class="Divider"></div><div id="https://www.notion.so/b62cdeb745074af88b521846652c3f71" class="Divider"></div><div id="https://www.notion.so/e6021b75afa84752a364f496149f4816" class="ColumnList"><div id="https://www.notion.so/db52f614ad4740be9ab72f8c09b09bff" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/632dfb716d114aab97f46df002dd4d6f" class="ColorfulBlock ColorfulBlock--BgGreen Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Introduction</strong></span></span></p></div><div id="https://www.notion.so/0b4054cede47421f9fa521a6343e11ab" class="ColorfulBlock ColorfulBlock--ColorGreen Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Definition</span></span></p></div><div id="https://www.notion.so/92be5a58d0d34e668baf8192061ef808" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Pose estimation is a computer vision task that infers the pose of a person or object in an image or video. This is typically done by identifying, locating, and tracking the number of¬†key points¬†on a given object or person. For objects, this could be corners or other significant features. And for humans, these key points represent major joints like an elbow or knee.</span></span></p></div><div id="https://www.notion.so/79c6a7862d6947069b71116a635074ec" class="ColorfulBlock ColorfulBlock--ColorGreen Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Applications</span></span></p></div><div id="https://www.notion.so/2654dab10ba0408c8aea3d8312c667a0" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Activity recognition, motion capture, fall detection, plank pose corrector, yoga pose identifier, body ration estimation</span></span></p></div><div id="https://www.notion.so/13d6133f793944339d4cdcd409afa3f0" class="ColorfulBlock ColorfulBlock--ColorGreen Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Scope</span></span></p></div><div id="https://www.notion.so/9822f51944dc4720a0b51159fe4b278a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">2D skeleton map (3D mapping coming soon)</span></span></p></div><div id="https://www.notion.so/db3b3da7dcbc4cf1b37f17bc22acab11" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Human Poses (product poses coming soon)</span></span></p></div><div id="https://www.notion.so/4efc8b7b143c4520ae93fc8e821e6c2a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Single and Multi-pose</span></span></p></div><div id="https://www.notion.so/e4ba35c6890b44b0be92bb99b245b24f" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Real-time</span></span></p></div><div id="https://www.notion.so/7447ed2c10dd4fe99f10134e698ad448" class="ColorfulBlock ColorfulBlock--ColorGreen Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Tools</span></span></p></div><div id="https://www.notion.so/d6dfefd4034a4605a523b5e20fcbc9e1" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Tensorflow PoseNet API</span></span></p></div></div><div id="https://www.notion.so/e93150b22053415cb9608c1a8ab6cdda" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/55b4ad3bf6fd4f98b856129d011fa989" class="ColorfulBlock ColorfulBlock--BgPink Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Models</strong></span></span></p></div><div id="https://www.notion.so/96f07a6983b244b0a0816dc8f8ceba4b" class="ColorfulBlock ColorfulBlock--ColorPink Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown">OpenPose</span></span></span></p></div><div id="https://www.notion.so/27951abd6f1a4468bd926e2c8d00412b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1812.08008"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields. arXiv, 2016.</em></a></span></span></p></div><div id="https://www.notion.so/7ce50de5b47d4462999a7b2a0ee7bbfb" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">A standard bottom-up model that supports real-time multi-person 2D pose estimation. The authors of the paper have shared two models ‚Äì one is trained on the Multi-Person Dataset ( MPII ) and the other is trained on the COCO dataset. The COCO model produces 18 points, while the MPII model outputs 15 points. </span></span></p></div><div id="https://www.notion.so/feec10e410634d2d8380c40fb9e6a5a0" class="ColorfulBlock ColorfulBlock--ColorPink Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown">PoseNet</span></span></span></p></div><div id="https://www.notion.so/16f686b67cbd4aabae3d411ef6df0ce5" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">PoseNet is a machine learning model that allows for Real-time Human Pose Estimation. PoseNet can be used to estimate either a single pose or multiple poses PoseNet v1 is trained on MobileNet backbone and v2 on ResNet backbone. </span></span></p></div><div id="https://www.notion.so/00d342b4a85344c182b5c591d672bd9e" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div></div></div><div id="https://www.notion.so/0c8bd5d7b8f94890af219d33e4e10b8b" class="Divider"></div><div id="https://www.notion.so/18032c9163ab45c694211b8085ac6e4c" class="ColumnList"><div id="https://www.notion.so/999c18f4f65c4191b211783d76a30a0a" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/336afb50b4614052b839c2de9747289a" class="ColorfulBlock ColorfulBlock--BgPurple Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Process flow</strong></span></span></p></div><div id="https://www.notion.so/ee718949657c4fa788281aeca4ec08fb" class="ColorfulBlock ColorfulBlock--ColorPurple Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Step 1: Collect Images</span></span></p></div><div id="https://www.notion.so/1b35ef2965344ad880d9d24006500bac" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Capture via camera, scrap from the internet or use public datasets</span></span></p></div><div id="https://www.notion.so/c492c2b37fe24306b812530e55ad5874" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedColor SemanticString__Fragment--ColorPurple">Step 2: Create Labels</mark></span></span></p></div><div id="https://www.notion.so/250d2b51cad441f8ac58e0ec0b9efb44" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Use a pre-trained model like PoseNet, OpenPose to identify the key points. These key points are our labels for pose estimation based classification task. If the model is not compatible/available for the required key points (e.g. identify the cap and bottom of a bottle product to measure if manufacturing is correct), we have to first train a pose estimation model using transfer learning in that case (this is out of scope though, as we are only focusing on human poses and pre-trained models are already available for this use case)</span></span></p></div><div id="https://www.notion.so/f7af8ea9093f4733b35530da8372378c" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedColor SemanticString__Fragment--ColorPurple">Step 3: Data Preparation</mark></span></span></p></div><div id="https://www.notion.so/6b4d21921f9d4323aebc43544d1da934" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Setup the database connection and fetch the data into the environment. Explore the data, validate it, and create a preprocessing strategy. Clean the data and make it ready for modeling</span></span></p></div><div id="https://www.notion.so/1f9ac2f951434220ac134115b913eae9" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedColor SemanticString__Fragment--ColorPurple">Step 4: Model Building</mark></span></span></p></div><div id="https://www.notion.so/e5903dde3cec4a5398aa37263636587a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Create the model architecture in python and perform a sanity check. Start the training process and track the progress and experiments. Validate the final set of models and select/assemble the final model</span></span></p></div><div id="https://www.notion.so/109b7af7deb042989759bd1b32cf61fb" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedColor SemanticString__Fragment--ColorPurple">Step 5: UAT Testing</mark></span></span></p></div><div id="https://www.notion.so/807edeb6d29a4ead9b4f134f5adfbc8b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Wrap the model inference engine in API for client testing</span></span></p></div><div id="https://www.notion.so/2ec5a1420ce844d6acede992f7f7c399" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedColor SemanticString__Fragment--ColorPurple">Step 6: Deployment</mark></span></span></p></div><div id="https://www.notion.so/b933b27dbfba4b35a327c31454282465" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Deploy the model on cloud or edge as per the requirement</span></span></p></div><div id="https://www.notion.so/764c546ce76a4f76b1519abe4f910565" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedColor SemanticString__Fragment--ColorPurple">Step 7: Documentation</mark></span></span></p></div><div id="https://www.notion.so/42a89d68eac84435bd6334a9a443dfcf" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Prepare the documentation and transfer all assets to the client  </span></span></p></div></div><div id="https://www.notion.so/5731e178ef4f4ff79c8611abec52a3b6" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/d24b76a079cb4bfdaf9334b684d29487" class="ColorfulBlock ColorfulBlock--BgBlue Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Use Cases</strong></span></span></p></div><div id="https://www.notion.so/24406ccc58f14852b53ac7753f67f5c3" class="ColorfulBlock ColorfulBlock--ColorBlue Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown">OpenPose Experiments</span></span></span></p></div><div id="https://www.notion.so/c9ebb7c31ee74911a5fc4e99f27b28ec" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Four types of experiments with pre-trained OpenPose model - Single and Multi-Person Pose Estimation with OpenCV, Multi-Person Pose Estimation with PyTorch and Pose Estimation on Videos. Check out </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="/7f01bee1534243f3836728d03a419969">this</a></span><span class="SemanticString"> notion.</span></span></p></div><div id="https://www.notion.so/68fccdebf7394e7890941ef45f044478" class="ColorfulBlock ColorfulBlock--ColorBlue Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown">Pose Estimation Inference Experiments</span></span></span></p></div><div id="https://www.notion.so/590c9689e9a646b0ad9ab0f5834e053d" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Experimented with pre-trained pose estimation models. Check out </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="/8cb982455e01478e876c52e9324d8e6b">this</a></span><span class="SemanticString"> notion for experiments with the OpenPifPaf model, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="/96e6aad0f36f44d3bff28e60525c6d31">this</a></span><span class="SemanticString"> one for the TorchVision Keypoint R-CNN model, and </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="/bb7f769860fa434d923feef3a99f9cbb#e0dd794e7aee477bb78ce855a1c909ee">this</a></span><span class="SemanticString"> notion for the Detectron2 model.</span></span></p></div><div id="https://www.notion.so/d078c8d8b740420aa6b4aa930787f20b" class="ColorfulBlock ColorfulBlock--ColorBlue Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown">Pose Detection on the Edge</span></span></span></p></div><div id="https://www.notion.so/7500594f71604ceea4f2ee79e5a9227c" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Train the pose detector using Teachable machine, employing the PoseNet model (multi-person real-time pose estimation) as the backbone and serve it to the web browser using ml5.js. This system will infer the end-users pose in real-time via a web browser. Check out </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://teachablemachine.withgoogle.com/train/pose">this</a></span><span class="SemanticString"> link and </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="/5661cefe46b449998cc31838441dc26a">this</a></span><span class="SemanticString"> notion. </span></span></p></div><div id="https://www.notion.so/d5e7c081ef72496f808b95d3a91b352a" class="ColorfulBlock ColorfulBlock--ColorBlue Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown">Pose Detection on the Edge using OpenVINO</span></span></span></p></div><div id="https://www.notion.so/2dd75bfe09a1452c8217d259538a9f38" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Optimize the pre-trained pose estimation model using the OpenVINO toolkit to make it ready to serve at the edge (e.g. small embedded devices) and create an OpenVINO inference engine for real-time inference. Check out </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="/4c4fc4f167cc4601ade5795a241a60da">this</a></span><span class="SemanticString"> notion.</span></span></p></div></div></div><div id="https://www.notion.so/f586f8ede0ab48079952f2194675dce5" class="Divider"></div><div id="https://www.notion.so/4cd136d21ba243e18aa2e2525144a1f1" class="Divider"></div></article>  <footer class="Footer">
        <div>&copy; Welcome to SparshAI 2019</div>
        <div>&centerdot;</div>
        <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
            rel="noopener noreferrer">Notablog</a>.
        </div>
    </footer>
</body>

</html>