<!DOCTYPE html>
<html lang="en">

<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-5F9Y9HC95G"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5F9Y9HC95G');
</script>
<script data-ad-client="ca-pub-8325812071117232" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <!-- Chrome, Firefox OS and Opera Status Bar Color -->
  <meta name="theme-color" content="#FFFFFF">
  <meta property="og:title" content="Image Classification">
    <meta property="og:type" content="blog">
  <title>Image Classification</title>
<link rel="icon" href="⚡"/>
  <!-- Favicon -->
    <link rel="shortcut icon" target="_blank" href="⚡">
    <link rel="stylesheet" type="text/css" target="_blank" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
  <link rel="stylesheet" type="text/css"
    target="_blank" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
  <link rel="stylesheet" type="text/css" target="_blank" href="css/SourceSansPro.css">
  <link rel="stylesheet" type="text/css" target="_blank" href="css/notablog.css">
  <link rel="stylesheet" type="text/css" target="_blank" href="css/theme.css">
  <style>
    :root {
      font-size: 18px;
    }

    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
    <a href="index">
      <div class="Navbar__Btn"><span>⚡</span> <span>Home</span></div>
    </a>
                                                                                                                                                                                                                                                                                                                                                                                                                                              </nav>
  <header class="Header">
          <div class="Header__Cover">
        <img src="https://www.notion.so/images/page-cover/met_camille_pissarro_1896.jpg">
      </div>
          <div class="Header__Spacer ">
    </div>
        <div class="Header__Icon"><span><img class="inline-img-icon" src="https://super.so/icon/dark/image.svg"></span></div>
        <h1 class="Header__Title">Image Classification</h1>
            <div class="DateTagBar">
                          <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--blue">
            <a target="_blank" href="tag/Vision">Vision</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--yellow">
            <a target="_blank" href="tag/Image classification">Image classification</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--default">
            <a target="_blank" href="tag/Notes">Notes</a>
          </span>
                  </div>
          </header>
      <article id="https://www.notion.so/75397bc8fb3348e7b206f2723864e281" class="PageRoot"><div id="https://www.notion.so/0950f0cc72314352934d2c36bdf0d38b" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb74535ed-dceb-4269-a944-a90275250614%2FUntitled.png?width=800&amp;table=block&amp;id=0950f0cc-7231-4352-934d-2c36bdf0d38b"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb74535ed-dceb-4269-a944-a90275250614%2FUntitled.png?width=800&amp;table=block&amp;id=0950f0cc-7231-4352-934d-2c36bdf0d38b" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/b5ae44a424b748e78454a93aff075da6" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/069996bf8fd540f3addd4c2167018b6a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Image classifier analyses an image and identifies the ‘class’ the image falls under. (Or a probability of the image being part of a ‘class’). A class is essentially a label, for instance, &#x27;car&#x27;, &#x27;animal&#x27;, &#x27;building&#x27;, and so on. Common applications are Automated Image Organization, Backbone for advanced tasks like object detection, pose estimation, action recognition etc.</span></span></p></div><h2 id="https://www.notion.so/74ee5ac84dd2488e8ece8fd6057438e0" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" target="_blank" href="#https://www.notion.so/74ee5ac84dd2488e8ece8fd6057438e0"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Models</span></span></h2><ol class="NumberedListWrapper"><li id="https://www.notion.so/9fe961a7009b4d33ac68482ba7aacd2f" class="NumberedList" value="1"><span class="SemanticStringArray"><span class="SemanticString">ResNet - </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://arxiv.org/abs/1512.03385"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">Deep Residual Learning for Image Recognition. ICLR, 2016.</em></a></span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic"> </em></span><span class="SemanticString">A very popular model that is often used as a backbone CNN to extract visual representations. It achieves a Top 1 accuracy of 76.1 on ImageNet (1000 categories).</span></span></li><li id="https://www.notion.so/922fc836ceec4ae5a73a6b99df43593c" class="NumberedList" value="2"><span class="SemanticStringArray"><span class="SemanticString">MobileNet - </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://arxiv.org/abs/1905.02244"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">Searching for MobileNetV3. ICCV, 2019.</em></a></span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic"> </em></span><span class="SemanticString">A lean mobile network that achieves an accuracy of 76.0 on ImageNet (1000 categories).</span></span></li><li id="https://www.notion.so/e620ae28c9044db7bf4e979a9e1ba1fa" class="NumberedList" value="3"><span class="SemanticStringArray"><span class="SemanticString">EfficientNet - </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://arxiv.org/abs/1905.11946"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. ICML, 2019.</em></a></span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic"> </em></span><span class="SemanticString">It achieves a Top 1 accuracy of 81.3 on ImageNet (1000 categories).</span></span></li><li id="https://www.notion.so/345ef9c6340447d5adcdf12a9e8822d9" class="NumberedList" value="4"><span class="SemanticStringArray"><span class="SemanticString">BiT - </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://arxiv.org/abs/1912.11370"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">Big Transfer (BiT): General Visual Representation Learning. arXiv, 2020.</em></a></span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic"> </em></span><span class="SemanticString">It achieves a Top 1 accuracy of 85.4 on ImageNet (1000 categories).</span></span></li><li id="https://www.notion.so/b54b3215f5124b03a269261ee9c92552" class="NumberedList" value="5"><span class="SemanticStringArray"><span class="SemanticString">ViT - </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://arxiv.org/abs/2010.11929"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. ICLR, 2021.</em></a></span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic"> </em></span><span class="SemanticString">It showed that the reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. This model achieves a Top 1 accuracy of 87.8 on ImageNet (1000 categories).</span></span></li></ol><h2 id="https://www.notion.so/635c876ce2ca473986fdc3855fc2e2da" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" target="_blank" href="#https://www.notion.so/635c876ce2ca473986fdc3855fc2e2da"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Use Cases</span></span></h2><ol class="NumberedListWrapper"><li id="https://www.notion.so/f40b0d11890e40cf80c97af35e6abfa9" class="NumberedList" value="1"><span class="SemanticStringArray"><span class="SemanticString">STL-10 Object Classification - Fine-tune a 10-class classifier in PyTorch. </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://nbviewer.jupyter.org/gist/sparsh-ai/9443e483250d7072d7fa6ac4062d7ae1">Notebook</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/cdfd2947a4f84a33a4b1aff9ce8203b5" class="NumberedList" value="2"><span class="SemanticStringArray"><span class="SemanticString">Flower Classification. </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://nbviewer.jupyter.org/gist/sparsh-ai/1fa06c1ee28b5b94c2181537f7cc8c27">Notebook + Gradio App</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/699afcc5eddd47b2a787e78afecb4460" class="NumberedList" value="3"><span class="SemanticStringArray"><span class="SemanticString">Cancer Image Classification - </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://nbviewer.jupyter.org/gist/sparsh-ai/dca65bfc01846700c0057def0f8316af">notebook</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/ce8b40e0e5f8464fbac1ed14b17b3c82" class="NumberedList" value="4"><span class="SemanticStringArray"><span class="SemanticString">Traffic Sign Classification - Train a 43-class image classifier from scratch in Keras. This is available as Streamlit App.</span></span></li><li id="https://www.notion.so/4df1bbc8ee3549f2966341371ca2a034" class="NumberedList" value="5"><span class="SemanticStringArray"><span class="SemanticString">Plant Disease Classification - Available as a Streamlit App.</span></span></li><li id="https://www.notion.so/c96febf26ded4341a6325f77d6486b33" class="NumberedList" value="6"><span class="SemanticStringArray"><span class="SemanticString">Brain Tumor Classification - Available as a Streamlit App</span></span></li><li id="https://www.notion.so/c18a96ca479344fd844641605735a409" class="NumberedList" value="7"><span class="SemanticStringArray"><span class="SemanticString">TorchVision Pre-trained Classifiers - PyTorch TorchVision provides more than 10 pre-trained image classification model, which can be easily fine-tuned on a custom image dataset. Here I experimented with VGG11, AlexNet, ResNet18, and MobileNetV2.</span></span></li><li id="https://www.notion.so/5dd949c94dce487abb53e07b65502baa" class="NumberedList" value="8"><span class="SemanticStringArray"><span class="SemanticString">EfficientNet Fine-tuning - Fine-tune EfficientNet in TF Keras to build a dog classifier. There are 120 classes of dogs. The data is available in Tensorflow datasets. Check out the blog </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/">here</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/6fb12cb718ea41f7ae920b09517d53f6" class="NumberedList" value="9"><span class="SemanticStringArray"><span class="SemanticString">BiT Fine-tuning - Fine-tune Big-Transfer few-shot model. This model is available in TFHub. Checkout this </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://colab.research.google.com/github/google-research/big_transfer/blob/master/colabs/big_transfer_tf2.ipynb">Colab</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/19b357e3621343278d990f3a233555b9" class="NumberedList" value="10"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://towardsdatascience.com/deploying-an-image-classification-web-app-with-python-3753c46bb79">Rock Paper Scissor Classifier Streamlit and Heroku</a></span></span></li></ol><div id="https://www.notion.so/82a2c683a7474fde86ec5ebecf19864a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">10. </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://jtwang1027.github.io/streamlit/">Multimodel Streamlit with GCP Load Test</a></span></span></p></div><div id="https://www.notion.so/a5084bb913914aebbd05ae22178d52df" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">11. </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://pypi.org/project/vision-transformer-pytorch/">ViT Pytorch Pip</a></span></span></p></div><div id="https://www.notion.so/71a3a712a5f445c79ec51687f326f2a2" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">12. </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://colab.research.google.com/github/google-research/vision_transformer/blob/master/vit_jax.ipynb">ViT Colab</a></span></span></p></div><h2 id="https://www.notion.so/c522d74a01d4462cb6ff1c2753e7ef43" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" target="_blank" href="#https://www.notion.so/c522d74a01d4462cb6ff1c2753e7ef43"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Links and References</span></span></h2><div id="https://www.notion.so/4a58c93cac7d4e6398983db2200b4726" class="Bookmark"><a target="_blank" href="https://colab.research.google.com/drive/1cqjZfxrVmujUSd2vq7qFxwRBk7MitVii#scrollTo=BTUxSHXyxY5e"><h5 class="Bookmark__Title">Google Colaboratory</h5><p class="Bookmark__Link">https://colab.research.google.com/drive/1cqjZfxrVmujUSd2vq7qFxwRBk7MitVii#scrollTo=BTUxSHXyxY5e</p></a></div><div id="https://www.notion.so/5020f7327e234d17a9b323a7ace9bc24" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div></article>  <footer class="Footer">
        <div>&copy; Sparsh Agarwal 2021</div>
        <div>&centerdot;</div>
        <div>Powered by <a target="_blank" href="https://github.com/dragonman225/notablog" target="_blank"
            rel="noopener noreferrer">Notablog</a>.
        </div>
    </footer>
</body>

</html>