<!DOCTYPE html>
<html lang="en">

<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-5F9Y9HC95G"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5F9Y9HC95G');
</script>
<script data-ad-client="ca-pub-8325812071117232" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <!-- Chrome, Firefox OS and Opera Status Bar Color -->
  <meta name="theme-color" content="#FFFFFF">
  <meta property="og:title" content="Video Action Recognition">
    <meta name="description" content="Video action recognition is the task of identifying human activities (e.g. eating, playing) in videos. Common applications include automated surveillance, elderly behavior monitoring, human-computer interaction, content-based video retrieval, and video summarization. 3D-ResNet and R(2+1)D are the two most common architectures for this task.">
  <meta property="og:description" content="Video action recognition is the task of identifying human activities (e.g. eating, playing) in videos. Common applications include automated surveillance, elderly behavior monitoring, human-computer interaction, content-based video retrieval, and video summarization. 3D-ResNet and R(2+1)D are the two most common architectures for this task.">
    <meta property="og:type" content="blog">
  <title>Video Action Recognition</title>
  <!-- Favicon -->
    <link rel="shortcut icon" href="ü§ñ">
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
  <link rel="stylesheet" type="text/css"
    href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
  <link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
  <link rel="stylesheet" type="text/css" href="css/notablog.css">
  <link rel="stylesheet" type="text/css" href="css/theme.css">
  <style>
    :root {
      font-size: 18px;
    }

    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
    <a href="index.html">
      <div class="Navbar__Btn"><span>ü§ñ</span> <span>Home</span></div>
    </a>
                                                                                                                                                                                                                                    <span class="Navbar__Delim">&centerdot;</span>
    <a href="extras.html">
      <div class="Navbar__Btn"><span>üì•</span> <span>Extras</span></div>
    </a>
                <span class="Navbar__Delim">&centerdot;</span>
    <a href="about.html">
      <div class="Navbar__Btn"><span>üßò‚Äç‚ôÇÔ∏è</span> <span>About</span></div>
    </a>
          </nav>
  <header class="Header">
          <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
        <h1 class="Header__Title">Video Action Recognition</h1>
            <div class="DateTagBar">
                <span class="DateTagBar__Item DateTagBar__Date">Posted on Tue, Dec 29, 2020</span>
                          <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--default">
            <a href="tag/poster.html">poster</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--gray">
            <a href="tag/video.html">video</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--blue">
            <a href="tag/action recognition.html">action recognition</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--orange">
            <a href="tag/computer vision.html">computer vision</a>
          </span>
                  </div>
          </header>
      <article id="https://www.notion.so/f1d3f8db7e7541e18232f60edcaf9654" class="PageRoot"><div id="https://www.notion.so/dbd56ffd63164841823f95473fbf36f4" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb0dcbe5d-bdfb-4229-bd27-d3bccb70e0ae%2Fimg.png?width=1200&amp;table=block&amp;id=dbd56ffd-6316-4841-823f-95473fbf36f4"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb0dcbe5d-bdfb-4229-bd27-d3bccb70e0ae%2Fimg.png?width=1200&amp;table=block&amp;id=dbd56ffd-6316-4841-823f-95473fbf36f4" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/cec95f50b3a145cea274124518efb6a7" class="Divider"></div><div id="https://www.notion.so/e0b7ee125f07468e910ab56274ba6f34" class="Divider"></div><div id="https://www.notion.so/d5763017c41b4213a635040fbaf2862c" class="ColorfulBlock ColorfulBlock--BgGreen Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Introduction</strong></span></span></p></div><div id="https://www.notion.so/5e2eae2d84374796a03c0d5d268aec5b" class="ColorfulBlock ColorfulBlock--ColorGreen Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Definition</span></span></p></div><div id="https://www.notion.so/447b394fc5094b939d68ba6aeda4eb5f" class="ColorfulBlock ColorfulBlock--BgGray Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">This is the task of identifying human activities/actions (e.g. eating, playing) in videos. In other words, this task classifies segments of videos into a set of pre-defined categories.</span></span></p></div><div id="https://www.notion.so/7968b402630447d495c7fa35af285460" class="ColorfulBlock ColorfulBlock--ColorGreen Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Applications</span></span></p></div><div id="https://www.notion.so/b5f9e7af487c427aa376da1f16c8ae68" class="ColorfulBlock ColorfulBlock--BgGray Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Automated surveillance, elderly behavior monitoring, human-computer interaction, content-based video retrieval, and video summarization.</span></span></p></div><div id="https://www.notion.so/216a46d252754befa493c9dd70da0b16" class="ColorfulBlock ColorfulBlock--ColorGreen Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Scope</span></span></p></div><div id="https://www.notion.so/3a0d20ff1ea846788e81045ab87fc4db" class="ColorfulBlock ColorfulBlock--BgGray Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Human Action only</span></span></p></div><div id="https://www.notion.so/1d8f7be241904bd6accb482613e43b2e" class="ColorfulBlock ColorfulBlock--ColorGreen Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Tools</span></span></p></div><div id="https://www.notion.so/8c976a1b76f44a0e8fedd5962d022a4a" class="ColorfulBlock ColorfulBlock--BgGray Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">OpenCV</span></span></p></div><div id="https://www.notion.so/0fe4882195a54563819f189381692e24" class="Divider"></div><div id="https://www.notion.so/6f86df71f39c45da8ea9d4d50f8cefe5" class="Divider"></div><div id="https://www.notion.so/9239c4d3e2cf449a8eb664c35c1f1e4f" class="ColorfulBlock ColorfulBlock--BgPink Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Models</strong></span></span></p></div><div id="https://www.notion.so/dbe3ce4d596e42b997541dc8eee87afa" class="ColorfulBlock ColorfulBlock--ColorPink Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown">3D-ResNet</span></span></span></p></div><div id="https://www.notion.so/d6d0f146881d401293204214c77dd428" class="ColorfulBlock ColorfulBlock--BgGray Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1711.09577"><em class="SemanticString__Fragment SemanticString__Fragment--Italic"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?</strong></em></a></span></span></p></div><div id="https://www.notion.so/0435d3b23b3b4dc1b223cf9d7b8da59e" class="ColorfulBlock ColorfulBlock--BgGray Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">the authors explore how existing state-of-the-art 2D architectures (such as ResNet, ResNeXt, DenseNet, etc.) can be extended to video classification via 3D kernels.</span></span></p></div><div id="https://www.notion.so/374498ac9f5b47bfb07dbbb2cc70b971" class="ColorfulBlock ColorfulBlock--ColorPink Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown">R(2+1)D</span></span></span></p></div><div id="https://www.notion.so/444aeeb8107d4412a7c377f6df2502dd" class="ColorfulBlock ColorfulBlock--BgGray Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">This model was pre-trained on 65 million social media videos and fine-tuned on Kinetics400. </span></span></p></div><div id="https://www.notion.so/6f7a0c6e322f443b84deeb9e3fb1cb4f" class="Divider"></div><div id="https://www.notion.so/653ccd34f7e544d991cec10149f2875f" class="Divider"></div><div id="https://www.notion.so/cb6e44c1d06e438da4f77710a3085945" class="ColorfulBlock ColorfulBlock--BgBlue Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Use Cases</strong></span></span></p></div><div id="https://www.notion.so/b19920d1c67b4cad89e24ee907c0b841" class="ColorfulBlock ColorfulBlock--ColorBlue Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown">Kinetics 3D CNN Human Activity Recognition</span></span></span></p></div><div id="https://www.notion.so/edae51754579446b81fa88cc52f1aa28" class="ColorfulBlock ColorfulBlock--BgGray Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">This dataset consists of 400 human activity recognition classes, at least 400 video clips per class¬†(downloaded via YouTube) and a total of 300,000 videos. Check out </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="/fd10fd7b5858459cba65dc4a6cb73630">this</a></span><span class="SemanticString"> notion.</span></span></p></div><div id="https://www.notion.so/8e22ac03e7b0422d895a335a7cdec59c" class="ColorfulBlock ColorfulBlock--ColorBlue Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">A</span><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown">ction Recognition using R(2+1)D Model</span></span></span></p></div><div id="https://www.notion.so/bec92b6ac6484944bfccae4d4f0a9b7f" class="ColorfulBlock ColorfulBlock--BgGray Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">VGA Annotator was used for creating the video annotation for training. Check out </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="/4c796f308aed40f29fc230a757af98e8">this</a></span><span class="SemanticString"> notion.</span></span></p></div><div id="https://www.notion.so/8e752463e9ee45249b8acc824d453774" class="Divider"></div><div id="https://www.notion.so/96ae8800e3f346eea9e6f02768a18857" class="Divider"></div></article>  <footer class="Footer">
        <div>&copy; Welcome to SparshAI 2021</div>
        <div>&centerdot;</div>
        <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
            rel="noopener noreferrer">Notablog</a>.
        </div>
    </footer>
</body>

</html>