<!DOCTYPE html>
<html lang="en">

<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-5F9Y9HC95G"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5F9Y9HC95G');
</script>
<script data-ad-client="ca-pub-8325812071117232" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <!-- Chrome, Firefox OS and Opera Status Bar Color -->
  <meta name="theme-color" content="#FFFFFF">
  <meta property="og:title" content="Extra Notes">
    <meta property="og:type" content="blog">
  <title>Extra Notes</title>
<link rel="icon" type="image/png" href="/favicon.png"/>
  <!-- Favicon -->
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
  <link rel="stylesheet" type="text/css"
    href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
  <link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
  <link rel="stylesheet" type="text/css" href="css/notablog.css">
  <link rel="stylesheet" type="text/css" href="css/theme.css">
  <style>
    :root {
      font-size: 18px;
    }

    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
    <a href="index">
      <div class="Navbar__Btn"> <span>Home</span></div>
    </a>
                                                                                                                    <span class="Navbar__Delim">&centerdot;</span>
    <a href="extras">
      <div class="Navbar__Btn"> <span>Extras</span></div>
    </a>
                <span class="Navbar__Delim">&centerdot;</span>
    <a href="about">
      <div class="Navbar__Btn"> <span>About</span></div>
    </a>
                <span class="Navbar__Delim">&centerdot;</span>
    <a href="news">
      <div class="Navbar__Btn"> <span>News</span></div>
    </a>
                                          </nav>
  <header class="Header">
          <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
        <h1 class="Header__Title">Extra Notes</h1>
          </header>
      <article id="https://www.notion.so/f75a676c35d3498d9ea22575f32c5b7c" class="PageRoot"><h2 id="https://www.notion.so/dfb2364095154069aebb342b0666a52b" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/dfb2364095154069aebb342b0666a52b"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Image to Image Translation</span></span></h2><div id="https://www.notion.so/4b391e7675e04e179dc9b431c176955e" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Many image processing, computer graphics, and computer vision problems can be treated as image-to-image translation tasks. Such translation entails learning to map one visual representation of a given input to another representation.</span></span></p></div><details id="https://www.notion.so/b1cf7d3b1dfe4bfbba4505359b9887cb" class="ColorfulBlock ColorfulBlock--ColorDefault Toggle "><summary class="Toggle__Summary"><span class="SemanticStringArray"><span class="SemanticString">Images</span></span></summary><div class="Toggle__Content"><div id="https://www.notion.so/0eb13ca1eda04cd39f435201a534842e" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F03a278b3-dd29-47da-8aa2-55759d642263%2FUntitled.png?width=1303&amp;table=block&amp;id=0eb13ca1-eda0-4cd3-9f43-5201a534842e"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F03a278b3-dd29-47da-8aa2-55759d642263%2FUntitled.png?width=1303&amp;table=block&amp;id=0eb13ca1-eda0-4cd3-9f43-5201a534842e" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/97f66c1443dc41ec9605eaecc3421465" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F18f9a736-8e5f-4767-a7a0-81f43189b085%2FUntitled.png?width=1154&amp;table=block&amp;id=97f66c14-43dc-41ec-9605-eaecc3421465"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F18f9a736-8e5f-4767-a7a0-81f43189b085%2FUntitled.png?width=1154&amp;table=block&amp;id=97f66c14-43dc-41ec-9605-eaecc3421465" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/a4dd203c26004432986016a8653e56c8" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fa2eab1ed-98f4-4988-b3ab-0b5f37b79e6e%2FUntitled.png?width=1004&amp;table=block&amp;id=a4dd203c-2600-4432-9860-16a8653e56c8"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fa2eab1ed-98f4-4988-b3ab-0b5f37b79e6e%2FUntitled.png?width=1004&amp;table=block&amp;id=a4dd203c-2600-4432-9860-16a8653e56c8" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/56309147bb6848abba8a87fb4385acf1" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff12d6c20-2040-4856-b349-277685e37bdf%2FUntitled.png?width=471&amp;table=block&amp;id=56309147-bb68-48ab-ba8a-87fb4385acf1"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff12d6c20-2040-4856-b349-277685e37bdf%2FUntitled.png?width=471&amp;table=block&amp;id=56309147-bb68-48ab-ba8a-87fb4385acf1" style="width:471px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Style control</span></span></figcaption></figure></div><div id="https://www.notion.so/653a8f8a891a4620b86060d062217925" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc7c90101-620e-45a3-9af9-6339758d8f98%2FUntitled.png?width=2125&amp;table=block&amp;id=653a8f8a-891a-4620-b860-60d062217925"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc7c90101-620e-45a3-9af9-6339758d8f98%2FUntitled.png?width=2125&amp;table=block&amp;id=653a8f8a-891a-4620-b860-60d062217925" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/487b40bd95024130a900d961a2d1456f" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc9528f64-7576-4e92-b748-33c852b04a47%2FUntitled.png?width=792&amp;table=block&amp;id=487b40bd-9502-4130-a900-d961a2d1456f"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc9528f64-7576-4e92-b748-33c852b04a47%2FUntitled.png?width=792&amp;table=block&amp;id=487b40bd-9502-4130-a900-d961a2d1456f" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/93466ef2dc064380a437ab435aa62456" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F233160a7-7114-43b6-95d5-c7d09f9fd570%2FUntitled.png?width=1226&amp;table=block&amp;id=93466ef2-dc06-4380-a437-ab435aa62456"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F233160a7-7114-43b6-95d5-c7d09f9fd570%2FUntitled.png?width=1226&amp;table=block&amp;id=93466ef2-dc06-4380-a437-ab435aa62456" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div></div></details><details id="https://www.notion.so/da9c6f070e704551aeda6077c444ff4a" class="ColorfulBlock ColorfulBlock--ColorDefault Toggle "><summary class="Toggle__Summary"><span class="SemanticStringArray"><span class="SemanticString">CVPR 2016 PPT Selected slides - Instead of hand-designing loss, GAN Discriminator is the learned loss function</span></span></summary><div class="Toggle__Content"><div id="https://www.notion.so/8887eee36d3645448e8c25ad6632ce6d" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2862d005-e8ec-4fdf-a9b4-fe59aa1adcb4%2FUntitled.png?width=851&amp;table=block&amp;id=8887eee3-6d36-4544-8e8c-25ad6632ce6d"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2862d005-e8ec-4fdf-a9b4-fe59aa1adcb4%2FUntitled.png?width=851&amp;table=block&amp;id=8887eee3-6d36-4544-8e8c-25ad6632ce6d" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/22cc3dc3b8f447eabc730eadc09a0b71" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe5f5a72c-6623-4c38-bd7d-6f81edfb630a%2FUntitled.png?width=463&amp;table=block&amp;id=22cc3dc3-b8f4-47ea-bc73-0eadc09a0b71"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe5f5a72c-6623-4c38-bd7d-6f81edfb630a%2FUntitled.png?width=463&amp;table=block&amp;id=22cc3dc3-b8f4-47ea-bc73-0eadc09a0b71" style="width:463px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/50a078ffc20c4f5b946b2e1794021b43" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0fe6b948-ef18-4c1b-a3ea-b2aa202f4290%2FUntitled.png?width=776&amp;table=block&amp;id=50a078ff-c20c-4f5b-946b-2e1794021b43"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0fe6b948-ef18-4c1b-a3ea-b2aa202f4290%2FUntitled.png?width=776&amp;table=block&amp;id=50a078ff-c20c-4f5b-946b-2e1794021b43" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/efe3acbc6ef34d689572413be8eb9ba3" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Feaf48203-f2ad-4a15-bfb8-0ae79539cafc%2FUntitled.png?width=610&amp;table=block&amp;id=efe3acbc-6ef3-4d68-9572-413be8eb9ba3"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Feaf48203-f2ad-4a15-bfb8-0ae79539cafc%2FUntitled.png?width=610&amp;table=block&amp;id=efe3acbc-6ef3-4d68-9572-413be8eb9ba3" style="width:610px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/9de55933855c4fecbd88bc4c917aba61" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fabe8f9d1-9f69-4bde-98b8-730861e1ebed%2FUntitled.png?width=782&amp;table=block&amp;id=9de55933-855c-4fec-bd88-bc4c917aba61"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fabe8f9d1-9f69-4bde-98b8-730861e1ebed%2FUntitled.png?width=782&amp;table=block&amp;id=9de55933-855c-4fec-bd88-bc4c917aba61" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div></div></details><details id="https://www.notion.so/cff70ad0dbf94a0b8b03db8458eca085" class="ColorfulBlock ColorfulBlock--ColorDefault Toggle "><summary class="Toggle__Summary"><span class="SemanticStringArray"><span class="SemanticString">Patch Discriminator</span></span></summary><div class="Toggle__Content"><div id="https://www.notion.so/46d8465e5d624257a2fc91b1bb5a674a" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff9585909-98fc-4263-bfde-7906266a5550%2FUntitled.png?width=796&amp;table=block&amp;id=46d8465e-5d62-4257-a2fc-91b1bb5a674a"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff9585909-98fc-4263-bfde-7906266a5550%2FUntitled.png?width=796&amp;table=block&amp;id=46d8465e-5d62-4257-a2fc-91b1bb5a674a" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div></div></details><details id="https://www.notion.so/bfa6d93a04704b739c77774712a3a544" class="ColorfulBlock ColorfulBlock--ColorDefault Toggle "><summary class="Toggle__Summary"><span class="SemanticStringArray"><span class="SemanticString">Pix2Pix</span></span></summary><div class="Toggle__Content"><div id="https://www.notion.so/1b30099f11a04408b79d19b7d8edd1f6" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">⭐ </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/">Blog guide</a></span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/971c1e18424f48f5874d649c30b6edf0" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Pix2Pix Browser </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://affinelayer.com/pixsrv/">demo</a></span></span></li></ul></div></details><details id="https://www.notion.so/f4bcb18f49f749d0b7f80433f6ed7426" class="ColorfulBlock ColorfulBlock--ColorDefault Toggle "><summary class="Toggle__Summary"><span class="SemanticStringArray"><span class="SemanticString">Inference</span></span></summary><div class="Toggle__Content"><ul class="BulletedListWrapper"><li id="https://www.notion.so/c614ec2db0de40388a7f62f29a877225" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">CycleGAN Pytorch </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://colab.research.google.com/github/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/CycleGAN.ipynb">colab</a></span></span></li><li id="https://www.notion.so/5d1e8f0c51b24c0a99131a361c080e19" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Pix2Pix Pytorch </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://colab.research.google.com/github/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb">colab</a></span></span></li></ul></div></details><details id="https://www.notion.so/43581bf494a540a38d0d306e2f1f5e2f" class="ColorfulBlock ColorfulBlock--ColorDefault Toggle "><summary class="Toggle__Summary"><span class="SemanticStringArray"><span class="SemanticString">Training</span></span></summary><div class="Toggle__Content"><ul class="BulletedListWrapper"><li id="https://www.notion.so/10c9c88931d7414682ca8bd1a2577ad0" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Train CycleGAN and Pix2Pix in Pytorch </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">here</a></span></span></li><li id="https://www.notion.so/fcd6b36e6ff340fdb275edd79c455494" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">CycleGAN from scratch </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://theailearner.com/tag/image-to-image-translation/">blog</a></span></span></li><li id="https://www.notion.so/239aea01bbf34ea1ad2b0a8d8ce7976b" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">CycleGAN from scratch </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://machinelearningmastery.com/cyclegan-tutorial-with-keras/">blog</a></span></span></li><li id="https://www.notion.so/faffec5a3680455fa1665d488f8ca1fa" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">CycleGAN from scratch </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://keras.io/examples/generative/cyclegan/">Keras Official</a></span></span></li><li id="https://www.notion.so/329e45aabd4046eebd99eced3025e80c" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Pix2Pix from scratch code </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/">blog</a></span></span></li><li id="https://www.notion.so/a01dd06343e24dcb8be6d60c659e3e0e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">StyleGAN2 custom training </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/dvschultz/stylegan2-ada">git</a></span></span></li><li id="https://www.notion.so/32a9a902578f4f38a3f51938133d80ff" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Custom Pix2PixHD </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://youtu.be/fXgodCC2O7o">youtube</a></span></span></li><li id="https://www.notion.so/e7f77c5536ba4239bc46f48c8f3c80d9" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Packt Notebooks </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/sparsh-ai/Deep-Learning-with-TensorFlow-2-and-Keras/tree/master/Chapter%206">git</a></span></span></li></ul></div></details><h2 id="https://www.notion.so/a0a687885f0b42128bcb22727bd0979f" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/a0a687885f0b42128bcb22727bd0979f"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Text to Image Translation</span></span></h2><div id="https://www.notion.so/13486a877ca14b3ca3f89828e9d90136" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Generating images from text descriptions is an interesting use case of GANs. This can be helpful in the film industry, as a GAN is capable of generating new data based on some text that you have made up. In the comic industry, it is possible to automatically generate sequences of a story.</span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/1448f5f6476d49bbaa6c98bc43817e61" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/paarthneekhara/text-to-image">https://github.com/paarthneekhara/text-to-image</a></span></span></li></ul><div id="https://www.notion.so/05fb91809f3842d989684a35d09a8eec" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe246dd2a-ab69-4d10-89a6-5ed6fddb172b%2FUntitled.png?width=1065&amp;table=block&amp;id=05fb9180-9f38-42d9-8968-4a35d09a8eec"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe246dd2a-ab69-4d10-89a6-5ed6fddb172b%2FUntitled.png?width=1065&amp;table=block&amp;id=05fb9180-9f38-42d9-8968-4a35d09a8eec" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/c32e665cf8314a99b667cac52ea113d2" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">TAC-GAN – Text Conditioned Auxiliary Classifier Generative Adversarial Network, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/pdf/1703.06412.pdf">[paper]</a></span><span class="SemanticString">, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/dashayushman/TAC-GAN">[github]</a></span></span></li><li id="https://www.notion.so/726db6b7e534494b96a2bd894980207b" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/pdf/1612.03242.pdf">[paper]</a></span><span class="SemanticString">, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/hanzhanggit/StackGAN">[github]</a></span></span></li><li id="https://www.notion.so/649ea0ef72fe44d9a9a4895dd5bf5c24" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Generative Adversarial Text to Image Synthesis, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/pdf/1605.05396.pdf">[paper]</a></span><span class="SemanticString">, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/paarthneekhara/text-to-image">[github]</a></span><span class="SemanticString">, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/reedscot/icml2016">[github]</a></span></span></li><li id="https://www.notion.so/223b82114e3b4ddb816c3db0fa44aa30" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Learning What and Where to Draw, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="http://www.scottreed.info/files/nips2016.pdf">[paper]</a></span><span class="SemanticString">, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/reedscot/nips2016">[github]</a></span></span></li></ul><div id="https://www.notion.so/b73d56fec4fd4088a80dfedaae6a5406" class="Bookmark"><a href="https://vision-explorer.allenai.org/text_to_image_generation"><h5 class="Bookmark__Title">Computer Vision Explorer</h5><p class="Bookmark__Desc">The AI2 Computer Vision Explorer offers demos of a variety of popular models - try, compare, and evaluate with your own images!</p><p class="Bookmark__Link">https://vision-explorer.allenai.org/text_to_image_generation</p></a></div><div id="https://www.notion.so/f0cfd9d2c5bf4fada405608a4a812aa5" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F178fed76-8303-42d0-81e0-942fad28aae8%2FUntitled.png?width=898&amp;table=block&amp;id=f0cfd9d2-c5bf-4fad-a405-608a4a812aa5"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F178fed76-8303-42d0-81e0-942fad28aae8%2FUntitled.png?width=898&amp;table=block&amp;id=f0cfd9d2-c5bf-4fad-a405-608a4a812aa5" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><h2 id="https://www.notion.so/d32edb8e55004fbd91cbf981bb9371dd" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/d32edb8e55004fbd91cbf981bb9371dd"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Image Generation</span></span></h2><div id="https://www.notion.so/347df9ae85464464b6e344e3a5d8dc91" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffbf77942-b393-4936-a1d2-153c1933839c%2FUntitled.png?width=640&amp;table=block&amp;id=347df9ae-8546-4464-b6e3-44e3a5d8dc91"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffbf77942-b393-4936-a1d2-153c1933839c%2FUntitled.png?width=640&amp;table=block&amp;id=347df9ae-8546-4464-b6e3-44e3a5d8dc91" style="width:640px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/6dbb8b09617a4da099219152e0097af9" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Generative networks can be used to generate realistic images after being trained on sample images. For example, if we want to generate new images of dogs, we can train a GAN on thousands of samples of images of dogs. Once the training has finished, the generator network will be able to generate new images that are different from the images in the training set. Image generation is used in marketing, logo generation, entertainment, social media, and so on. In the next chapter, we will be generating faces of anime characters.</span></span></p></div><h3 id="https://www.notion.so/078e8bf87d6a46bbaa68b0b6a2fe6516" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/078e8bf87d6a46bbaa68b0b6a2fe6516"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Latent Space Representation</span></span></h3><div id="https://www.notion.so/005c1d74a78d483eae8751c376f3365c" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3f5caf06-bab4-4dff-bce7-8a87e43ff2c9%2FUntitled.png?width=486&amp;table=block&amp;id=005c1d74-a78d-483e-ae87-51c376f3365c"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3f5caf06-bab4-4dff-bce7-8a87e43ff2c9%2FUntitled.png?width=486&amp;table=block&amp;id=005c1d74-a78d-483e-ae87-51c376f3365c" style="width:486px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/37728e148e524cc4a4a773c7fe7c8d5c" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/7e0a40d14ade4f008277b55a9471f8b5" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">CONCEPT VECTORS FOR IMAGE EDITING</strong></span></span></span></p></div><div id="https://www.notion.so/a5f0a3fac1b04f2baa767324f4d33d8c" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Given a latent space of representations, or an embedding space, certain directions in the space may encode interesting axes of variation in the original data. In a latent space of images of faces, for instance, there may be a smile vector, such that if latent point z is the embedded representation of a certain face, then latent point z + s is the embedded representation of the same face, smiling.</span></span></p></div><div id="https://www.notion.so/e55a1fff6acd4cc9b9085a1b0e7e3b43" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F1e81abb6-e4bf-435b-bcf5-e1162dab8d63%2FUntitled.png?width=539&amp;table=block&amp;id=e55a1fff-6acd-4cc9-b908-5a1b0e7e3b43"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F1e81abb6-e4bf-435b-bcf5-e1162dab8d63%2FUntitled.png?width=539&amp;table=block&amp;id=e55a1fff-6acd-4cc9-b908-5a1b0e7e3b43" style="width:539px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/a5b0bc3c5b3644cda5aac44c50056295" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">There are concept vectors for essentially any independent dimension of variation in image space—in the case of faces, you may discover vectors for adding sunglasses to a face, removing glasses, turning a male face into as female face, and so on.</span></span></p></div><div id="https://www.notion.so/fb284a678fcb4ba5b4420e22c64bab14" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Variational Autoencoder (VAE)</strong></span></span></span></p></div><div id="https://www.notion.so/bc2bf61433dc47e6a76a33f5aa741ccb" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">A VAE turns the image into the parameters of a statistical distribution: a mean and variance. Essentially, this means you’re assuming the input image has been generated by a statistical process, and that the randomness of this process should be taken into account during encoding and decoding. The VAE then uses the mean and variance parameters to randomly sample one element of the distribution and decodes that element back to the original input. The stochasticity of this process improves robustness and forces the latent space to encode meaningful representations everywhere: every point sampled in the latent space is decoded to a valid output.</span></span></p></div><div id="https://www.notion.so/73790bd0fb0e4d4696e07a9bcc10c56d" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F73854a1b-4553-4655-8aab-8c05352e0d5d%2FUntitled.png?width=549&amp;table=block&amp;id=73790bd0-fb0e-4d46-96e0-7a9bcc10c56d"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F73854a1b-4553-4655-8aab-8c05352e0d5d%2FUntitled.png?width=549&amp;table=block&amp;id=73790bd0-fb0e-4d46-96e0-7a9bcc10c56d" style="width:549px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/cec8a138573746a6a9826250bec66dbf" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">The parameters of a VAE are trained via two loss functions: a reconstruction loss that forces the decoded samples to match the initial inputs, and a regularization loss that helps learn well-formed latent spaces and reduce overfitting to the training data.</span></span></p></div><div id="https://www.notion.so/dd0809d6a14f42aab219409cdad189dc" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Experiments</strong></span></span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/42cf7a5dc3164cf4acc97693bfc4c48a" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.tensorflow.org/tutorials/generative/dcgan">TF 2.0 DCGAN for digit generation</a></span></span></li><li id="https://www.notion.so/15aadb15b03b4ac28a25001bf1f62ed1" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.tensorflow.org/tutorials/generative/cvae">TF 2.0 VAE for digit generation</a></span></span></li><li id="https://www.notion.so/467633eb4d71421da17ee62e18331aff" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/PacktPublishing/Deep-Learning-with-PyTorch-1.x/blob/master/Chapter07/DCGAN.ipynb">Packt DCGAN</a></span></span></li><li id="https://www.notion.so/844506594f8541fabcacb118a2ba09d4" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/PacktPublishing/Hands-On-Neural-Network-Programming-with-TensorFlow/tree/master/Section%206">Packt Exercise</a></span></span></li><li id="https://www.notion.so/2174a52fd8634d7bbb8de46447b264f4" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter13">Packt</a></span></span></li><li id="https://www.notion.so/f27a496327a54fc5bf4a87df20336892" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/ageron/handson-ml2/blob/master/17_autoencoders_and_gans.ipynb">Packt</a></span></span></li><li id="https://www.notion.so/591d21828ffd4488a066214a80d5db3e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb">BigGAN Colab</a></span></span></li><li id="https://www.notion.so/247b9ae1c1eb4bf3afb4af238617ef54" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://colab.research.google.com/github/chainer-community/chainer-colab-notebook/blob/master/official_example_en/dcgan.ipynb">DCGAN Colab</a></span></span></li><li id="https://www.notion.so/5552695e47534b15b241e087fa723c9b" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://colab.research.google.com/github/lexfridman/mit-deep-learning/blob/master/tutorial_gans/tutorial_gans.ipynb">BigGAN MIT</a></span></span></li><li id="https://www.notion.so/6704a0f4eb4840f9a87c22b5875752da" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://colab.research.google.com/drive/1jsraJtjodGnJZoWF6O_rDxsQUgIrsslb">StyleGAN and BigGAN Colab</a></span></span></li></ul><h2 id="https://www.notion.so/71368f67b25a491fbbe19890cecd9ba2" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/71368f67b25a491fbbe19890cecd9ba2"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">3D Object Generation</span></span></h2><ul class="BulletedListWrapper"><li id="https://www.notion.so/bf6edc4d46d54c2ca22abfc8c68b725d" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Parametric 3D Exploration with Stacked Adversarial Networks, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/maxorange/pix2vox">[github]</a></span><span class="SemanticString">, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.youtube.com/watch?v=ITATOXVvWEM">[youtube]</a></span></span></li><li id="https://www.notion.so/ee608fc02d664b4f9b83f6ccf81b75cb" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Learning a Probabilistic Latent Space of Object
Shapes via 3D Generative-Adversarial Modeling, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="http://papers.nips.cc/paper/6096-learning-a-probabilistic-latent-space-of-object-shapes-via-3d-generative-adversarial-modeling.pdf">[paper]</a></span><span class="SemanticString">, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/zck119/3dgan-release">[github]</a></span><span class="SemanticString">, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.youtube.com/watch?v=HO1LYJb818Q">[youtube]</a></span></span></li><li id="https://www.notion.so/da4cbb46a6eb45daa217f8093870f15d" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">3D Shape Induction from 2D Views of Multiple Objects, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/pdf/1612.05872.pdf">[paper]</a></span></span></li><li id="https://www.notion.so/62d8dfe98dfa43a4923f422e1357f29c" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Fully Convolutional Refined Auto-Encoding Generative Adversarial Networks for 3D Multi Object Scenes, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/yunishi3/3D-FCR-alphaGAN">[github]</a></span><span class="SemanticString">, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://becominghuman.ai/3d-multi-object-gan-7b7cee4abf80">[blog]</a></span></span></li></ul><div></div><h2 id="https://www.notion.so/bdbe2d2159304ec2a79ad6ba5e9e2936" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/bdbe2d2159304ec2a79ad6ba5e9e2936"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Optical Character Recognition</span></span></h2><div id="https://www.notion.so/c1df7a37dae74ec384f7323b47c8bdc6" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F35ec3fc3-5b83-42fb-8cf4-04a56d11934f%2FUntitled.png?width=680&amp;table=block&amp;id=c1df7a37-dae7-4ec3-84f7-323b47c8bdc6"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F35ec3fc3-5b83-42fb-8cf4-04a56d11934f%2FUntitled.png?width=680&amp;table=block&amp;id=c1df7a37-dae7-4ec3-84f7-323b47c8bdc6" style="width:680px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/e1c440cd3df7488e913a72cb5b8c75c6" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/e33ffc25ee3048beb94513c0c0b1c340" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Optical Character Recognition(OCR) has been an active area of research in AI and Computer Vision. It enables us to Recognize(identify) text from images or PDF. OCR has a variety of applications like Data Entry for Business, Number Plate Recognition, Automated Passport Recognition, Quick Document Verification, IoT Application, Task Automation, etc. This Application has the potential to increase revenue and save time.</span></span></p></div><div id="https://www.notion.so/5f890688c63c4bb6b39fc27c4104ed8c" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Bag of Tricks</strong></span></span></span></p></div><div id="https://www.notion.so/eea703ede0af47cdb05186a2279a5b55" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">For Blur, Noisy and colorful image we need to follow some image-processing steps like making image black and white, remove salt and pepper noise using lowpass filters such as averaging filters or Gaussian Filter, We can also make blur image sharpen by using Highpass filter such as Sobel filters. This Image Processing operation can also be implemented by the OpenCV library in python.</span></span></p></div><div id="https://www.notion.so/5fdc87c079f64e8bb2d286e8a02a3800" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><span class="SemanticString__Fragment SemanticString__Fragment--Unknown"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Tools</strong></span></span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/058145efb96e42a2b6df65f057d929a9" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Keras-OCR</span></span></li></ul><details id="https://www.notion.so/177207dbba6f4ad6a04c58b26b145714" class="ColorfulBlock ColorfulBlock--ColorDefault Toggle "><summary class="Toggle__Summary"><span class="SemanticStringArray"><span class="SemanticString">Tesseract</span></span></summary><div class="Toggle__Content"><div id="https://www.notion.so/f1489d6f4e6f4b65b635ad477e32fa5f" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Pros:</strong></span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/df08ff2c3a114201a4c2274c773df93d" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Easy to use</span></span></li><li id="https://www.notion.so/4b1441c8773d487fa5281543eab136bb" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Fast Detection</span></span></li><li id="https://www.notion.so/2be63c95630345faa1e3b6068219f698" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Most Popular</span></span></li><li id="https://www.notion.so/c1c614fc08fa458daa1f861bdefe82b6" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Most efficient</span></span></li><li id="https://www.notion.so/5d1f060757974e8784eb36c40cfe3bf2" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Support 100+ Language</span></span></li><li id="https://www.notion.so/d2c4fa247c2243598e9367dc418f5035" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Oldest OCR Library</span></span></li><li id="https://www.notion.so/4d7488963e214ed7872f85bdd585243c" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Command-line support</span></span></li></ul><div id="https://www.notion.so/068164e9cec5448ca66d4dacbcfaeb21" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Cons:</strong></span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/ea436231d4b14cb99543698c1d0ee349" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Only works on CPU</span></span></li><li id="https://www.notion.so/2240763408aa42109fb4829ad1303b41" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Doesn’t perform well on Blur, Noisy and colorful image</span></span></li><li id="https://www.notion.so/9782c03b05114801a619fe5f472495fb" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Performance decrease for lower font size in low-resolution images</span></span></li><li id="https://www.notion.so/ff58e3945a354c0997d720c03abc5ba5" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Doesn’t work well on complex Forms</span></span></li></ul></div></details><details id="https://www.notion.so/62b23785650349f8aa0fd2c9b2cdc3b8" class="ColorfulBlock ColorfulBlock--ColorDefault Toggle "><summary class="Toggle__Summary"><span class="SemanticStringArray"><span class="SemanticString">EasyOCR</span></span></summary><div class="Toggle__Content"><div id="https://www.notion.so/ab45be5df7ad49b68baf51dd1cbb329f" class="Bookmark"><a href="https://github.com/JaidedAI/EasyOCR"><h5 class="Bookmark__Title">JaidedAI/EasyOCR</h5><p class="Bookmark__Desc">Ready-to-use OCR with 70+ languages supported including Chinese, Japanese, Korean and Thai. 17 November 2020 - Version 1.2 New language supports for Telugu and Kannada. These are experimental lite recognition models. Their file sizes are only around 7% of other models and they are ~6x faster at inference with CPU.</p><p class="Bookmark__Link">https://github.com/JaidedAI/EasyOCR</p></a></div><div id="https://www.notion.so/3688f64255724af887896273f99fe1f8" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">It&#x27;s one of the best open-source Multilingual libraries for OCR. It supports 70+ languages currently and more will be added soon. Due to the open-source nature and python support, it&#x27;s easy to add new languages in Easy OCR. It is Built on top of PyTorch, ResNet, CTC, and beam-search-based decoder.</span></span></p></div></div></details><details id="https://www.notion.so/90e6419625ff46f8a70c0246dd46d954" class="ColorfulBlock ColorfulBlock--ColorDefault Toggle Toggle--Empty"><summary class="Toggle__Summary"><span class="SemanticStringArray"><span class="SemanticString">ArabicOCR</span></span></summary><div class="Toggle__Content"></div></details></article>  <footer class="Footer">
        <div>&copy; Sparsh Agarwal 2021</div>
        <div>&centerdot;</div>
        <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
            rel="noopener noreferrer">Notablog</a>.
        </div>
    </footer>
</body>

</html>