<!DOCTYPE html>
<html lang="en">

<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-5F9Y9HC95G"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5F9Y9HC95G');
</script>
<script data-ad-client="ca-pub-8325812071117232" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <!-- Chrome, Firefox OS and Opera Status Bar Color -->
  <meta name="theme-color" content="#FFFFFF">
  <meta property="og:title" content="Practical AI - Part 1">
    <meta name="description" content="Frameworks, Tools, Models and Use¬†cases">
  <meta property="og:description" content="Frameworks, Tools, Models and Use¬†cases">
    <meta property="og:type" content="blog">
  <title>Practical AI - Part 1</title>
  <!-- Favicon -->
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
  <link rel="stylesheet" type="text/css"
    href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
  <link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
  <link rel="stylesheet" type="text/css" href="css/notablog.css">
  <link rel="stylesheet" type="text/css" href="css/theme.css">
  <style>
    :root {
      font-size: 18px;
    }

    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
    <a href="index.html">
      <div class="Navbar__Btn"> <span>Home</span></div>
    </a>
                                                                                                                                                                                                                                            <span class="Navbar__Delim">&centerdot;</span>
    <a href="extras.html">
      <div class="Navbar__Btn"> <span>Extras</span></div>
    </a>
                <span class="Navbar__Delim">&centerdot;</span>
    <a href="about.html">
      <div class="Navbar__Btn"> <span>About</span></div>
    </a>
          </nav>
  <header class="Header">
          <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
        <h1 class="Header__Title">Practical AI - Part 1</h1>
            <div class="DateTagBar">
                <span class="DateTagBar__Item DateTagBar__Date">Posted on Sat, Jan 9, 2021</span>
                          <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--orange">
            <a href="tag/frameworks.html">frameworks</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--orange">
            <a href="tag/computer vision.html">computer vision</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--default">
            <a href="tag/object detection.html">object detection</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--yellow">
            <a href="tag/image classification.html">image classification</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--pink">
            <a href="tag/image segmentation.html">image segmentation</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--purple">
            <a href="tag/vector similarity.html">vector similarity</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--pink">
            <a href="tag/deployment.html">deployment</a>
          </span>
                  </div>
          </header>
      <article id="https://www.notion.so/d8344abf65ac4e66892e5ee4463f3d40" class="PageRoot"><div id="https://www.notion.so/355cc8ca29bd49a4beb6c8b79831cd46" class="ColorfulBlock ColorfulBlock--BgBlue Callout"><div class="Callout__Icon"><div class="Icon">üëâüèª</div></div><p class="Callout__Content"><span class="SemanticStringArray"><span class="SemanticString">Frameworks, Tools, Models and Use¬†cases</span></span></p></div><h1 id="https://www.notion.so/923d2e5cab8b41b482c65ebee0ae58f4" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/923d2e5cab8b41b482c65ebee0ae58f4"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Problem Solving¬†Process</span></span></h1><h3 id="https://www.notion.so/418526e58ea54a5f98880c974aabca27" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/418526e58ea54a5f98880c974aabca27"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Step 1: Problem</strong></span></span></h3><div id="https://www.notion.so/57db5da70921423e9521ed273a2a8ab3" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Understand the business and current process (AS-IS process). Understand the problem/objective and define the problem statement. Identify the key performance indicators.</span></span></p></div><h3 id="https://www.notion.so/381f3c5a9b944a61a20f0ee8e1d86c87" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/381f3c5a9b944a61a20f0ee8e1d86c87"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Step 2: Plan</strong></span></span></h3><div id="https://www.notion.so/50836b6f046f4630a293d0c3837dd870" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Design the solution framework. Propose a solution. AS-IS vs. TO-BE process. Create the project plan with a timeline. Define the scope and initial set of hypotheses.</span></span></p></div><h3 id="https://www.notion.so/10512c9920124b4d935e33b1f164f6ec" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/10512c9920124b4d935e33b1f164f6ec"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Step 3: Data</strong></span></span></h3><div id="https://www.notion.so/cdb6d10cd44c4cf1a06513faa3b900f0" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Acquire the data. Perform exploratory analysis. Add data version control. Preprocess and Prepare the data for modeling.</span></span></p></div><h3 id="https://www.notion.so/ff72797d68eb4f7d8bb54e51fcacd947" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/ff72797d68eb4f7d8bb54e51fcacd947"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Step 4: Model</strong></span></span></h3><div id="https://www.notion.so/f737c0bc4022417eac040898e045bb31" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Design/select the model architecture, Model training, Optimization and tuning, Model validation. DEV and UAT testing.</span></span></p></div><h3 id="https://www.notion.so/2109881bfa804abfaa32b50cac08d3bf" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/2109881bfa804abfaa32b50cac08d3bf"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Step 5: Solution</strong></span></span></h3><div id="https://www.notion.so/91648bb7d3c94a339cd59f5496b3c7b3" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Containerization. Model serving via API and UI interface. Model pruning and quantization for serving at the edge. Technical and business-level documentation. Knowledge transfer via recorded sessions.</span></span></p></div><div id="https://www.notion.so/f6ca9e1c67a94f9c82518f648020247b" class="Divider"></div><h1 id="https://www.notion.so/832b28d2459a4fcbb453a14d08fc3941" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/832b28d2459a4fcbb453a14d08fc3941"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Experimentation Process</span></span></h1><h3 id="https://www.notion.so/3b14a4b03e41437ba113022ca7948f98" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/3b14a4b03e41437ba113022ca7948f98"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">1. Introduction</strong></span></span></h3><div id="https://www.notion.so/86e36917bfcd4e768f43526ce41fff10" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Begin by understanding the subject as a subject matter expert and think about the problem in natural language.</span></span></p></div><h3 id="https://www.notion.so/56e4a48c31d849ecb4cb1962e690eb73" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/56e4a48c31d849ecb4cb1962e690eb73"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">2. Methodology</strong></span></span></h3><div id="https://www.notion.so/683e31e3ba3c424eb6ef7d3d41011b7a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Make a mathematical description of a problem. Mathematics is not an option in AI, but a prerequisite. Literature review if required. Write the analysis with words and mathematics to make sure the reasoning reflects the subject.</span></span></p></div><h3 id="https://www.notion.so/ea1d095d489c4eb284103b606f281dde" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/ea1d095d489c4eb284103b606f281dde"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">3. Experimentation</strong></span></span></h3><div id="https://www.notion.so/3bce538bb4414571a22c3e52981b53cc" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Implementation of the proposed solution. Writing code. Training, testing, and validation of AI models.</span></span></p></div><h3 id="https://www.notion.so/008cf21a76d948f29a4e8ab937a89dee" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/008cf21a76d948f29a4e8ab937a89dee"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">4. Results &amp; Discussion</strong></span></span></h3><div id="https://www.notion.so/c9e43bfb1e2f49ea90daaa40674d1072" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Summarizing and discussing the results. Generating business insights. Explaining the results to business stakeholders.</span></span></p></div><div id="https://www.notion.so/a7e8c3ca307844caad9d48858c4c5fa0" class="Divider"></div><h1 id="https://www.notion.so/2f11bfd9981844c2a74eb40ac7fdc061" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/2f11bfd9981844c2a74eb40ac7fdc061"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Deployment Process</strong></span></span></h1><div id="https://www.notion.so/5597bbbcf5e547d3b6994af5b147fa3a" class="Image Image--PageWidth"><figure><a href="#"><img src="#" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/ee99fe4a28fa40ed9a4280243145936d" class="Divider"></div><h1 id="https://www.notion.so/9034f91a56b740698f74af6f5427636b" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/9034f91a56b740698f74af6f5427636b"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Image Classification</span></span></h1><div id="https://www.notion.so/aa9a533caad245069c0e36b4c8f25aa4" class="Image Image--PageWidth"><figure><a href="#"><img src="#" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/aae4a64f137a4f1dbb044e1bd1cda367" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">Image classification model analyzes an image and identifies the ‚Äòclass‚Äô the image falls under. (Or a probability of the image being part of a ‚Äòclass‚Äô). A class is essentially a label, for instance, ‚Äòcar‚Äô, ‚Äòanimal‚Äô, ‚Äòbuilding‚Äô, and so on.</em></span></span></p></div><h2 id="https://www.notion.so/7c7f19baa9dd49668f1e51030c586282" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/7c7f19baa9dd49668f1e51030c586282"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Models</span></span></h2><h3 id="https://www.notion.so/04aedf6756464d0b87a79b8f88a0f116" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/04aedf6756464d0b87a79b8f88a0f116"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">ResNet</strong></span></span></h3><div id="https://www.notion.so/f20bd658759e45c697cd656d5022e041" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1512.03385"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">Deep Residual Learning for Image Recognition. ICLR, 2016.</em></a></span></span></p></div><div id="https://www.notion.so/d8457f99d10a44e2b684590384a0e38f" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">A very popular model that is often used as a backbone CNN to extract visual representations. It achieves a Top 1 accuracy of 76.1 on ImageNet (1000 categories).</span></span></p></div><h3 id="https://www.notion.so/86d0534afb9a4dceb7dc0cfb57d14345" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/86d0534afb9a4dceb7dc0cfb57d14345"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">MobileNet</strong></span></span></h3><div id="https://www.notion.so/84600f8c81424fd7b78739ed5a471480" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1905.02244"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">Searching for MobileNetV3. ICCV, 2019.</em></a></span></span></p></div><div id="https://www.notion.so/3fc83e2b951a4c5d923a60f4b36327f0" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">A lean mobile network that achieves an accuracy of 76.0 on ImageNet (1000 categories).</span></span></p></div><h3 id="https://www.notion.so/c6bff411735b452a99a14be8a7219efa" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/c6bff411735b452a99a14be8a7219efa"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">EfficientNet</strong></span></span></h3><div id="https://www.notion.so/9a3556700b494f2898b70f2fc4134479" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1905.11946"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. ICML, 2019.</em></a></span></span></p></div><div id="https://www.notion.so/262def8c38f549ce838a3712f308fc03" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">It achieves a Top 1 accuracy of 81.3 on ImageNet (1000 categories).</span></span></p></div><h3 id="https://www.notion.so/d0f1b0273e5b426e878efa0c7ac9b755" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/d0f1b0273e5b426e878efa0c7ac9b755"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">BiT</strong></span></span></h3><div id="https://www.notion.so/ea4d91a7e4cd4677a2e2c465e995209d" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1912.11370"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">Big Transfer (BiT): General Visual Representation Learning. arXiv, 2020.</em></a></span></span></p></div><div id="https://www.notion.so/3eae677899ce4b5290f29ad980984ded" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">It achieves a Top 1 accuracy of 85.4 on ImageNet (1000 categories).</span></span></p></div><h3 id="https://www.notion.so/95dc29186d114e64812137dd6d4432d3" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/95dc29186d114e64812137dd6d4432d3"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">ViT</strong></span></span></h3><div id="https://www.notion.so/17691c987a794fe8abf00344e8c7ce2c" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/2010.11929"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. ICLR, 2021.</em></a></span></span></p></div><div id="https://www.notion.so/7c3bb165dc9d4b9d9723fa51f412808b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">It showed that the reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. This model achieves a Top 1 accuracy of 87.8 on ImageNet (1000 categories).</span></span></p></div><h2 id="https://www.notion.so/f8570ebf2a514002a200fc0edd005691" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/f8570ebf2a514002a200fc0edd005691"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Use Cases</span></span></h2><ol class="NumberedListWrapper"><li id="https://www.notion.so/684ad4ce3cfe497782cb5537af8d9e0b" class="NumberedList" value="1"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Flower Classification - </strong></span><span class="SemanticString">Gradio App available. Check out </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Flower-Classification-3afadec78f274940bcf35a8433a4ac9d">this</a></span><span class="SemanticString"> notion.</span></span></li><li id="https://www.notion.so/e89bcc8fae6f40b0863978e05737be97" class="NumberedList" value="2"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Traffic Sign Classification - </strong></span><span class="SemanticString">Train a 43-class image classifier from scratch in Keras. This is available as Streamlit App. A tutorial video is also available </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Traffic-Sign-Classification-from-Scratch-using-CNN-4ed7e0b9ad184c52871f13a1a1821f0e">here</a></span><span class="SemanticString"> on the notion.</span></span></li><li id="https://www.notion.so/929b33ba004044c1b7ff720e70958851" class="NumberedList" value="3"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">STL-10 Object Classification - </strong></span><span class="SemanticString">Fine-tune a 10-class classifier in PyTorch. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/STL-10-Image-Classification-in-PyTorch-a08568d0551c4a4fb5f06d18cc4ba7f2">here</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/952ed0a37a7844cb82160a2e57384572" class="NumberedList" value="4"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Plant Disease Classification - </strong></span><span class="SemanticString">Available as a Streamlit App</span></span></li><li id="https://www.notion.so/9aeb107e8169412aa1a1c995d05f9064" class="NumberedList" value="5"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Brain Tumor Classification - </strong></span><span class="SemanticString">Available as a Streamlit App</span></span></li><li id="https://www.notion.so/f6d904c5c46947ac91ae106d4058fd3d" class="NumberedList" value="6"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">TorchVision Pre-trained Classifiers - </strong></span><span class="SemanticString">PyTorch TorchVision provides more than 10 pre-trained image classification model, which can be easily fine-tuned on a custom image dataset. Here I experimented with VGG11, AlexNet, ResNet18, and MobileNetV2.</span></span></li><li id="https://www.notion.so/23687885452f47248add211df92a34dd" class="NumberedList" value="7"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">EfficientNet Fine-tuning - </strong></span><span class="SemanticString">Fine-tune EfficientNet in TF Keras to build a dog classifier. There are 120 classes of dogs. The data is available in TensorFlow datasets. The notion is available </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Image-classification-via-fine-tuning-with-EfficientNet-e16c131ad0054aff8798e1e496f36d32">here</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/4fc9761ef7fe48f5b762d6bdaa7324a0" class="NumberedList" value="8"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">BiT Fine-tuning - </strong></span><span class="SemanticString">Fine-tune Big-Transfer few-shot model. This model is available in TFHub. Checkout </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://colab.research.google.com/github/google-research/big_transfer/blob/master/colabs/big_transfer_tf2.ipynb">Colab</a></span><span class="SemanticString">.</span></span></li></ol><div id="https://www.notion.so/ec889a6d366c42a4bba394def44c056e" class="Divider"></div><h1 id="https://www.notion.so/aec5e858f8bc4793960b976ce0c26d66" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/aec5e858f8bc4793960b976ce0c26d66"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Image Similarity</span></span></h1><div id="https://www.notion.so/bdd0667b37ce46fc8d35ee589de04cbf" class="Image Image--PageWidth"><figure><a href="#"><img src="#" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/7536812c341f4a31a2237682b3b834e0" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">Image similarity is the measure of how similar two images are. In other words, it quantifies the degree of similarity between intensity patterns in two images.</em></span></span></p></div><div id="https://www.notion.so/0608435b275f4982b892134b87b0745f" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Applications‚Ää‚Äî‚Ää</strong></span><span class="SemanticString">Duplicate product detection, image clustering, visual search, product recommendations.</span></span></p></div><h2 id="https://www.notion.so/100444d6b2fc48eabadf35957e555dec" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/100444d6b2fc48eabadf35957e555dec"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Models</span></span></h2><h3 id="https://www.notion.so/09584916871c48b0a9d783548541a51f" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/09584916871c48b0a9d783548541a51f"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">DeepRank</strong></span></span></h3><div id="https://www.notion.so/acc2907ecc8e43bea7f0d6364de1bc5d" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1710.05649"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">DeepRank: A New Deep Architecture for Relevance Ranking in Information Retrieval. arXiv, 2017.</em></a></span></span></p></div><h3 id="https://www.notion.so/f0ede93e8cf342779ccd140afaee4add" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/f0ede93e8cf342779ccd140afaee4add"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">ConvNets</strong></span></span></h3><div id="https://www.notion.so/63e5be3e9435499cae36338cb29ee049" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Pre-trained models like MobileNet, EfficientNet, BiT-L/BiT-M can be used to convert images into vectors. These models can be found on TFHub. For more accuracy, fine-tuning can be done.</span></span></p></div><h3 id="https://www.notion.so/8bbb8665675b45cd9012924d26156551" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/8bbb8665675b45cd9012924d26156551"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">FAISS</strong></span></span></h3><div id="https://www.notion.so/835e0accd6bb4e95b04296d4b4138035" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1702.08734"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">Billion-scale similarity search with GPUs. arXiv, 2017.</em></a></span></span></p></div><div id="https://www.notion.so/e01332a0d49c4b7880ca8bc73b96c62c" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">FAISS is a library for efficient similarity search and clustering of dense vectors.</span></span></p></div><h3 id="https://www.notion.so/52fa7da0ac59490bbad78bf17e4fbff1" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/52fa7da0ac59490bbad78bf17e4fbff1"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Siamese Network</strong></span></span></h3><div id="https://www.notion.so/dcf885de142e4ce0b0969b5c12d6cd2a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Siamese network is a neural network that contains two or more identical subnetwork. The purpose of this network is to find the similarity or comparing the relationship between two comparable things. Unlike the classification task that uses cross-entropy as the loss function, the Siamese network usually uses contrastive loss or triplet loss.</span></span></p></div><h3 id="https://www.notion.so/d669900561e74725a5cd472a540fa8bd" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/d669900561e74725a5cd472a540fa8bd"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Similarity Measures</strong></span></span></h3><div id="https://www.notion.so/ee20e49f0a8849d7af579ff9d4b9fe65" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">L1 (Manhattan distance), L2 (Euclidean distance), Hinge Loss for Triplets.</span></span></p></div><h2 id="https://www.notion.so/1d722153bf13488f810f9f5313ee97bb" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/1d722153bf13488f810f9f5313ee97bb"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Use Cases</span></span></h2><ol class="NumberedListWrapper"><li id="https://www.notion.so/36e98eb726cb468196a654b8d87afe0c" class="NumberedList" value="1"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Multi-endpoint API Similarity System - </strong></span><span class="SemanticString">The task was to build an API that will support multiple endpoints. Each endpoint supports a separate similarity system. We built 2 endpoints: endpoint 1 would find Top-K most similar fashion images and endpoint 2 would find top-K most similar food images. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Multi-endpoint-Image-Similarity-System-159b47b635ea42299a0214551630e740">here</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/ad396e986019469cac9066668093b531" class="NumberedList" value="2"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Beanstalk Image Similarity System - </strong></span><span class="SemanticString">There are 2 endpoints in the API‚Ää‚Äî‚Ääone for training and the other for inference. During training, the system will receive a zipped file of images. At the time of inference, this trained system would receive an image over inference endpoint and send back top-K most similar images with a confidence score. The API was deployed on AWS beanstalk. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Image-Similarity-AWS-b8f33261750047a69744e91a554eabff">here</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/921231785d174af684772410195c396a" class="NumberedList" value="3"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Image + Text Similarity - </strong></span><span class="SemanticString">Use the textual details and images of products, find the exact similar product among different groups. Around 35 GB of retail product images was scraped and used to build the system. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Image-Text-Similarity-fe5130324ae14ab48a30c93444348f4a">here</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/7916b3a9e6c24470b5b0ff8664bd3781" class="NumberedList" value="4"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Siamese Network Image Similarity on MNIST - </strong></span><span class="SemanticString">Siamese networks are incredibly powerful networks, responsible for significant increases in face recognition, signature verification, and prescription pill identification applications. The objective was to build image pairs for the Siamese network, train the Siamese network with TF Keras, and then compare image similarity with this Siamese network.</span></span></li><li id="https://www.notion.so/3840578598b94844a17e91da657dc68f" class="NumberedList" value="5"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Visual Recommendation - </strong></span><span class="SemanticString">Use image similarity to recommend users visually similar products based on what they searched. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Image-Similarity-Detection-in-Action-with-Tensorflow-2-0-c2b4421d75dd42a3a1becf9c98251ccb">here</a></span><span class="SemanticString">.</span></span></li></ol><div id="https://www.notion.so/aee1b627226c4a2a962a88500d62795b" class="Divider"></div><h1 id="https://www.notion.so/7753cfb3debc4aa5816155e45d822a73" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/7753cfb3debc4aa5816155e45d822a73"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Object Detection</span></span></h1><div id="https://www.notion.so/5c37a73c0e09470c83893fd63c14f8c5" class="Image Image--PageWidth"><figure><a href="#"><img src="#" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/5bfec4bededd41fbb24646f2262c3e07" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">Object detection is a computer vision technique that allows us to identify and locate objects in an image or video.</em></span></span></p></div><div id="https://www.notion.so/9abdfbb46efa4504bfaf244359c3b4a0" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Applications‚Ää‚Äî‚Ää</strong></span><span class="SemanticString">Crowd counting, Self-driving cars, Video surveillance, Face detection, Anomaly detection.</span></span></p></div><div id="https://www.notion.so/3456591ad1894c18af480b0c347f8775" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Tools‚Ää‚Äî‚Ää</strong></span><span class="SemanticString">Detectron2, TF Object Detection API, OpenCV, TFHub, TorchVision.</span></span></p></div><h2 id="https://www.notion.so/2baf92235a56467ca04710830e8dce54" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/2baf92235a56467ca04710830e8dce54"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Models</span></span></h2><h3 id="https://www.notion.so/c8f7295d0d8744f2bc3baa80c643ae4b" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/c8f7295d0d8744f2bc3baa80c643ae4b"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Faster R-CNN</strong></span></span></h3><div id="https://www.notion.so/d5468f036bac43a38cc699be9654f9ea" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1506.01497"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. arXiv, 2016.</em></a></span></span></p></div><h3 id="https://www.notion.so/472bb7b3f94e41e5b2d93fd6f450c430" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/472bb7b3f94e41e5b2d93fd6f450c430"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">SSD (Single Shot Detector)</strong></span></span></h3><div id="https://www.notion.so/f200428cfe6140c18d7931f8bbde2b58" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1512.02325"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">SSD: Single Shot MultiBox Detector. CVPR, 2016.</em></a></span></span></p></div><h3 id="https://www.notion.so/3610f4e7bf304f35b15b3425009a118d" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/3610f4e7bf304f35b15b3425009a118d"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">YOLO (You Only Look Once)</strong></span></span></h3><div id="https://www.notion.so/be7bf6f448c84fa7b4fd882a2df41e86" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1804.02767"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">YOLOv3: An Incremental Improvement. arXiv, 2018.</em></a></span></span></p></div><h3 id="https://www.notion.so/58407747137647c5abeed57db5e307a7" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/58407747137647c5abeed57db5e307a7"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">EfficientDet</strong></span></span></h3><div id="https://www.notion.so/04c3e2eb3e6046e4854a43349ec0cd94" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1911.09070"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">EfficientDet: Scalable and Efficient Object Detection. CVPR, 2020.</em></a></span></span></p></div><div id="https://www.notion.so/2b5664359c264dbb87c3fefe1d5b4202" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">It achieved 55.1 AP on COCO test-dev with 77M parameters.</span></span></p></div><h2 id="https://www.notion.so/cfa20063dd8a4db091f0f6086830d6e8" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/cfa20063dd8a4db091f0f6086830d6e8"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Use Cases</span></span></h2><ol class="NumberedListWrapper"><li id="https://www.notion.so/f09484ea6bef4cf1b0aa94137c6b50a7" class="NumberedList" value="1"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Automatic License Plate Recognition - </strong></span><span class="SemanticString">Recognition of vehicle license plate number using various methods including YOLO4 object detector and Tesseract OCR. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Automatic-License-Plate-Recognition-10ec22181b454b1facc99abdeadbf78f">here</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/aa31c55579bc45aab277594aac4dbc34" class="NumberedList" value="2"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Object Detection App - </strong></span><span class="SemanticString">This is available as a Streamlit app. It detects common objects. 3 models are available for this task‚Ää‚Äî‚ÄäCaffe MobileNet-SSD, Darknet YOLO3-tiny, and Darknet YOLO3. Along with common objects, this app also detects human faces and fire. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Object-Detector-App-c60fddae2fcd426ab763261436fb15d8">here</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/7c301107934743eba4cb9e9e9a31f68a" class="NumberedList" value="3"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Logo Detector - </strong></span><span class="SemanticString">Build a REST API to detect logos in images. API will receive 2 zip files‚Ää‚Äî‚Ää1) a set of images in which we must find the logo and 2) an image of the logo. Deployed the model in AWS Elastic Beanstalk. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Logo-Detection-91bfe4953dcf4558807b342efe05a9ff">here</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/2654ff6f5a034c45aead6604ea62abc3" class="NumberedList" value="4"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">TF Object Detection API Experiments - </strong></span><span class="SemanticString">The TensorFlow Object Detection API is an open-source framework built on top of TensorFlow that makes it easy to construct, train, and deploy object detection models. We did inference on pre-trained models, few-shot training on single class, few-shot training on multiple classes and conversion to TFLite model. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Tensorflow-Object-Detection-API-499b017e502d4950a9d448fb35a41d58">here</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/800bc64f6b6e466cac4c310d721a27b0" class="NumberedList" value="5"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Pre-trained Inference Experiments - </strong></span><span class="SemanticString">Inference on 6 pre-trained models‚Ää‚Äî‚ÄäInception-ResNet (TFHub), SSD-MobileNet (TFHub), PyTorch YOLO3, PyTorch SSD, PyTorch Mask R-CNN, and EfficientDet. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Object-Detection-Inference-Experiments-568fa092b1d34471b676fd43a42974b2">here</a></span><span class="SemanticString"> and </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Object-Detection-Inference-with-Pre-trained-models-da9e2e5bfab944bc90f568f6bc4b3e1f">here</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/9262a47a868c4b71b2252259b167f44b" class="NumberedList" value="6"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Object Detection App - </strong></span><span class="SemanticString">TorchVision Mask R-CNN model Gradio App. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/MaskRCNN-TorchVision-Object-Detection-Demo-c22f2a13ab63493b9b38720b20c50051">here</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/5b9632255aaa4fbda8fcdccc14c721b0" class="NumberedList" value="7"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Real-time Object Detector in OpenCV - </strong></span><span class="SemanticString">Build a model to detect common objects like scissors, cups, bottles, etc. using the MobileNet SSD model in the OpenCV toolkit. It will task input from the camera and detect objects in real-time. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Object-Detection-with-OpenCV-MobileNet-SSD-38ff496d2f0d427185a9c51cebc1ddf2">here</a></span><span class="SemanticString">. Available as a Streamlit app also (this app is not real-time).</span></span></li><li id="https://www.notion.so/0a8b8080047543f88fb406805470c8dd" class="NumberedList" value="8"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">EfficientDet Fine-tuning - </strong></span><span class="SemanticString">Fine-tune YOLO4 model on new classes. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/EfficientDet-fine-tuning-01a6ffd1e11f4dc1941073aff4b9b486">here</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/d0a26f61d9c0433a883e0c822297afe2" class="NumberedList" value="9"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">YOLO4 Fine-tuning - </strong></span><span class="SemanticString">Fine-tune YOLO4 model on new classes. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/YOLO-4-b32c2d2a4b8644b59f1c05e6887ffcca">here</a></span><span class="SemanticString">.</span></span></li><li id="https://www.notion.so/7969e838dbd0467d9ce896fc572ff621" class="NumberedList" value="10"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Detectron2 Fine-tuning - </strong></span><span class="SemanticString">Fine-tune Detectron2 Mask R-CNN (with PointRend) model on new classes. Checkout the notion </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/YOLO-4-b32c2d2a4b8644b59f1c05e6887ffcca">here</a></span><span class="SemanticString">.</span></span></li></ol><div id="https://www.notion.so/1468e1ccde394485868b20d59b3b96a4" class="Divider"></div><h1 id="https://www.notion.so/91b8e44c7f7c4163a6fa3585cba553ff" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/91b8e44c7f7c4163a6fa3585cba553ff"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Image Segmentation</span></span></h1><div id="https://www.notion.so/1997a4cf9f684a309a0e761a38e82ccd" class="Image Image--PageWidth"><figure><a href="#"><img src="#" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/650d072683c643d8b0861b9c88ae08f5" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">Image segmentation is the task of assigning labels to each pixel of an image.</em></span></span></p></div><div id="https://www.notion.so/e6a674f79d5742e79fc8ee8b626a10de" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Applications‚Ää‚Äî‚Ää</strong></span><span class="SemanticString">Medical imaging, self-driving cars, satellite imaging.</span></span></p></div><div id="https://www.notion.so/4c610a50905d4c9490cb1ce4e91011b6" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Tools‚Ää‚Äî‚Ää</strong></span><span class="SemanticString">Detectron2, TFHub, TorchVision, DeepLab.</span></span></p></div><h2 id="https://www.notion.so/1c3946cfb58c4353b2368b6960817bc4" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/1c3946cfb58c4353b2368b6960817bc4"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Models</span></span></h2><h3 id="https://www.notion.so/4c03d0b0e00445039356bdad54563720" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/4c03d0b0e00445039356bdad54563720"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">U-Net</strong></span></span></h3><div id="https://www.notion.so/8fab69d83bc24c4e910fcac031562eed" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1505.04597"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">U-Net: Convolutional Networks for Biomedical Image Segmentation. arXiv, 2015.</em></a></span></span></p></div><div id="https://www.notion.so/0ab9c0c210b24768aca231a688a0bee0" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">It was originally designed to perform medical image segmentation, but it works well on a wide variety of tasks, from segmenting cells on microscope images to detecting ships or houses on photos taken from satellites.</span></span></p></div><h3 id="https://www.notion.so/971e6142fb8247958d2a8ea3d2c06053" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/971e6142fb8247958d2a8ea3d2c06053"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Mask R-CNN</strong></span></span></h3><div id="https://www.notion.so/cb2aa75bc0754a86a5fee5168f01edd2" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1703.06870"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">Mask R-CNN. arXiv, 2017.</em></a></span></span></p></div><div id="https://www.notion.so/9b5559a724f2445baed0ce3a0e90fe63" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">The Mask R-CNN framework is built on top of Faster R-CNN. ****So, for a given image, Mask R-CNN, in addition to the class label and bounding box coordinates for each object, will also return the object mask.</span></span></p></div><h3 id="https://www.notion.so/9ac4c801a5ce4eb381522f0ccac71b5e" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/9ac4c801a5ce4eb381522f0ccac71b5e"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">DeepLabV3+</strong></span></span></h3><div id="https://www.notion.so/c72f189490a44e76aa2e1cac66d09b5f" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://arxiv.org/abs/1802.02611"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation. arXiv, 2018.</em></a></span></span></p></div><div id="https://www.notion.so/09275429483b4ad0a0164eb2957d64e8" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">It achieves a mean IOU score of 89% on the PASCAL VOC 2012 dataset.</span></span></p></div><h2 id="https://www.notion.so/bc1f2b108608455fb4de3839b1ef2e98" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/bc1f2b108608455fb4de3839b1ef2e98"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Use Cases</span></span></h2><ol class="NumberedListWrapper"><li id="https://www.notion.so/756781325368422babe98e0de1d0583a" class="NumberedList" value="1"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Satellite Image Segmentation for Agricultural Fields - </strong></span><span class="SemanticString">An image with 1800 x 1135 resolution and 60 channels. Every Month 5 bands images were shot from agricultural land for 12 months. There is 8 type of croplands. The task is to classify all unknown label pixels into one of these 8 categories. U-Net model was trained from scratch on patches. Checkout </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Satellite-Image-Segmentation-for-Agricultural-Fields-9914b549617746578c509e0382deb211">this</a></span><span class="SemanticString"> notion.</span></span></li><li id="https://www.notion.so/99ced10dc68a46ceae286d73c36de194" class="NumberedList" value="2"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Detectron2 Fine-tuning - </strong></span><span class="SemanticString">Fine-tune Detectron2 Mask R-CNN (with PointRend) model on new classes. It supports semantic, instance, and panoptic segmentation. We fine-tuned on balloons, chipsets, and faces. Checkout </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Detectron-2-bb7f769860fa434d923feef3a99f9cbb">this</a></span><span class="SemanticString"> notion.</span></span></li><li id="https://www.notion.so/e0b942f07fc64d93abe0f3f77ba6ad8b" class="NumberedList" value="3"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Industrial Use Cases for Image Segmentation - </strong></span><span class="SemanticString">Experimented with 3 industrial use cases‚Ää‚Äî‚ÄäCarvana Vehicle Image Masking, Airbus Ship Detection, and Severstal Steel Defect Detection. Checkout </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Kaggle-Image-Segmentation-Experiments-770728c2ef9a493da20863789b112d78">this</a></span><span class="SemanticString"> notion.</span></span></li><li id="https://www.notion.so/4164d6b171504ca9b6048e2cdb48d520" class="NumberedList" value="4"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Real-time segmentation on Videos - </strong></span><span class="SemanticString">Real-time tracking and segmentation with Siam Mask, semantic segmentation with LightNet++ and instance segmentation with YOLACT. Checkout </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Image-Segmentation-Inference-Experiments-26fac32c220f419a902121129b2924db">this</a></span><span class="SemanticString"> notion.</span></span></li><li id="https://www.notion.so/1293c65c63814253b93b12e9c993003d" class="NumberedList" value="5"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Image Segmentation Exercises - </strong></span><span class="SemanticString">Thresholding with Otsu and Riddler‚ÄìCalvard, Image segmentation with self-organizing maps, Random Walk segmentation with Scikit-image, Skin color segmentation with the GMM‚ÄìEM algorithm, Medical image segmentation, Deep semantic segmentation, Deep instance segmentation. Checkout </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/Image-Segmentation-Exercises-cc3262c55d374fb684362f5d333fb91a">this</a></span><span class="SemanticString"> notion.</span></span></li><li id="https://www.notion.so/fe75ef2a54d54d09b9fc0abb6cdba973" class="NumberedList" value="6"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">TorchVision Inference Experiments - </strong></span><span class="SemanticString">FCN-ResNet and DeepLabV3 (both are available in TorchVision library) inference. Available as a Streamlit app. Checkout </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/FCN-ResNet-vs-DeepLab-App-5168fac2ed0b42b1ad95a0b9e8b26d53">this</a></span><span class="SemanticString"> notion.</span></span></li></ol></article>  <footer class="Footer">
        <div>&copy; Sparsh Agarwal 2019</div>
        <div>&centerdot;</div>
        <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
            rel="noopener noreferrer">Notablog</a>.
        </div>
    </footer>
</body>

</html>