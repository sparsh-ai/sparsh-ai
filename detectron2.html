<!DOCTYPE html>
<html lang="en">

<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-5F9Y9HC95G"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5F9Y9HC95G');
</script>
<script data-ad-client="ca-pub-8325812071117232" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <!-- Chrome, Firefox OS and Opera Status Bar Color -->
  <meta name="theme-color" content="#FFFFFF">
  <meta property="og:title" content="Detectron 2">
    <meta property="og:type" content="blog">
  <title>Detectron 2</title>
<link rel="icon" href="⚡"/>
  <!-- Favicon -->
    <link rel="shortcut icon" href="⚡">
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
  <link rel="stylesheet" type="text/css"
    href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
  <link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
  <link rel="stylesheet" type="text/css" href="css/notablog.css">
  <link rel="stylesheet" type="text/css" href="css/theme.css">
  <style>
    :root {
      font-size: 18px;
    }

    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
    <a href="index">
      <div class="Navbar__Btn"><span>⚡</span> <span>Home</span></div>
    </a>
                                                                                                                                                                                                                                    <span class="Navbar__Delim">&centerdot;</span>
    <a href="notes">
      <div class="Navbar__Btn"><span><img class="inline-img-icon" src="https://super.so/icon/dark/folder.svg"></span> <span>Notes</span></div>
    </a>
                        <span class="Navbar__Delim">&centerdot;</span>
    <a href="about">
      <div class="Navbar__Btn"><span><img class="inline-img-icon" src="https://super.so/icon/dark/send.svg"></span> <span>About</span></div>
    </a>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  </nav>
  <header class="Header">
          <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
        <h1 class="Header__Title">Detectron 2</h1>
            <div class="DateTagBar">
                <span class="DateTagBar__Item DateTagBar__Date">Posted on Mon, Jan 4, 2021</span>
                            </div>
          </header>
      <article id="https://www.notion.so/982870b6622c43da9c7043d9171254fa" class="PageRoot"><div id="https://www.notion.so/74cc62ff0fc440b0a0cfd2b8cb8f2b5f" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3d5bb330-275c-4a02-854b-6a38d15090b8%2FUntitled.png?width=1347&amp;table=block&amp;id=74cc62ff-0fc4-40b0-a0cf-d2b8cb8f2b5f"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3d5bb330-275c-4a02-854b-6a38d15090b8%2FUntitled.png?width=1347&amp;table=block&amp;id=74cc62ff-0fc4-40b0-a0cf-d2b8cb8f2b5f" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><h1 id="https://www.notion.so/ec50c35965fd4d4c8469ba6e261511fb" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/ec50c35965fd4d4c8469ba6e261511fb"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Introduction</span></span></h1><div id="https://www.notion.so/15bd8ddf664b4d569a7bcc236dacfa82" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Detectron 2 is a next-generation open-source object detection system from Facebook AI Research. With the repo you can use and train the various state-of-the-art models for detection tasks such as bounding-box detection, instance and semantic segmentation, and person keypoint detection.</span></span></p></div><div id="https://www.notion.so/69a0e1b93d5c4a908d4b73cf1f039f10" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">The following is the directory tree of detectron 2:</span></span></p></div><pre id="https://www.notion.so/6b66dcb5a7db4b51b16696b1d0c065f2" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>detectron2
├─checkpoint  &lt;- checkpointer and model catalog handlers
├─config      &lt;- default configs and handlers
├─data        &lt;- dataset handlers and data loaders
├─engine      &lt;- predictor and trainer engines
├─evaluation  &lt;- evaluator for each dataset
├─export      &lt;- converter of detectron2 models to caffe2 (ONNX)
├─layers      &lt;- custom layers e.g. deformable conv.
├─model_zoo   &lt;- pre-trained model links and handler
├─modeling   
│  ├─meta_arch &lt;- meta architecture e.g. R-CNN, RetinaNet
│  ├─backbone  &lt;- backbone network e.g. ResNet, FPN
│  ├─proposal_generator &lt;- region proposal network
│  └─roi_heads &lt;- head networks for pooled ROIs e.g. box, mask heads
├─solver       &lt;- optimizer and scheduler builders
├─structures   &lt;- structure classes e.g. Boxes, Instances, etc
└─utils        &lt;- utility modules e.g. visualizer, logger, etc</span></span></span></code></pre><h1 id="https://www.notion.so/e4f53600606e48b693a0f81e48b278f4" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/e4f53600606e48b693a0f81e48b278f4"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Installation</span></span></h1><pre id="https://www.notion.so/366a28bb497e473bb3aa5d89a80745e6" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span><span class="token operator">%</span><span class="token operator">%</span>time
!pip install <span class="token operator">-</span>U torch<span class="token operator">==</span><span class="token number">1.4</span><span class="token operator">+</span>cu100 torchvision<span class="token operator">==</span><span class="token number">0.5</span><span class="token operator">+</span>cu100 <span class="token operator">-</span>f https<span class="token punctuation">:</span><span class="token operator">//</span>download<span class="token punctuation">.</span>pytorch<span class="token punctuation">.</span>org<span class="token operator">/</span>whl<span class="token operator">/</span>torch_stable<span class="token punctuation">.</span>html<span class="token punctuation">;</span>
!pip install cython pyyaml<span class="token operator">==</span><span class="token number">5.1</span><span class="token punctuation">;</span>
!pip install <span class="token operator">-</span>U <span class="token string">'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'</span><span class="token punctuation">;</span>
!pip install detectron2 <span class="token operator">-</span>f https<span class="token punctuation">:</span><span class="token operator">//</span>dl<span class="token punctuation">.</span>fbaipublicfiles<span class="token punctuation">.</span>com<span class="token operator">/</span>detectron2<span class="token operator">/</span>wheels<span class="token operator">/</span>cu100<span class="token operator">/</span>index<span class="token punctuation">.</span>html<span class="token punctuation">;</span>

<span class="token keyword">from</span> detectron2 <span class="token keyword">import</span> model_zoo
<span class="token keyword">from</span> detectron2<span class="token punctuation">.</span>engine <span class="token keyword">import</span> DefaultPredictor
<span class="token keyword">from</span> detectron2<span class="token punctuation">.</span>config <span class="token keyword">import</span> get_cfg
<span class="token keyword">from</span> detectron2<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>visualizer <span class="token keyword">import</span> Visualizer
<span class="token keyword">from</span> detectron2<span class="token punctuation">.</span>data <span class="token keyword">import</span> MetadataCatalog</span></span></span></code></pre><h1 id="https://www.notion.so/fa517b74f6b740f7ab1d0ea19d0930aa" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/fa517b74f6b740f7ab1d0ea19d0930aa"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Inference on pre-trained models</span></span></h1><div id="https://www.notion.so/a58f15ef12934477bd08fd0bff79f725" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffeaf135e-a211-420b-8cdb-24dc6cc932e5%2FUntitled.png?width=672&amp;table=block&amp;id=a58f15ef-1293-4477-bd08-fd0bff79f725"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffeaf135e-a211-420b-8cdb-24dc6cc932e5%2FUntitled.png?width=672&amp;table=block&amp;id=a58f15ef-1293-4477-bd08-fd0bff79f725" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Original image</span></span></figcaption></figure></div><div id="https://www.notion.so/a0aebd17c7f5427c9a6fa31b790975a7" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F23f21d25-a97b-44b3-b45e-17f69b5385b5%2FUntitled.png?width=744&amp;table=block&amp;id=a0aebd17-c7f5-427c-9a6f-a31b790975a7"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F23f21d25-a97b-44b3-b45e-17f69b5385b5%2FUntitled.png?width=744&amp;table=block&amp;id=a0aebd17-c7f5-427c-9a6f-a31b790975a7" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Object detection with Faster-RCNN-101</span></span></figcaption></figure></div><div id="https://www.notion.so/a5f6365d361042f2a68119b25cd14812" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F345be1d0-0c2f-4084-be4b-02c22422b930%2FUntitled.png?width=744&amp;table=block&amp;id=a5f6365d-3610-42f2-a681-19b25cd14812"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F345be1d0-0c2f-4084-be4b-02c22422b930%2FUntitled.png?width=744&amp;table=block&amp;id=a5f6365d-3610-42f2-a681-19b25cd14812" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Instance segmentation with Mask-RCNN-50</span></span></figcaption></figure></div><div id="https://www.notion.so/fa2974f43f7148139898dd70d99f7cd2" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/aee8b225d04c4c25a10927454946d3a6" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F19c46bd9-c2fb-4999-a1a7-b2d54db62dbb%2FUntitled.png?width=744&amp;table=block&amp;id=aee8b225-d04c-4c25-a109-27454946d3a6"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F19c46bd9-c2fb-4999-a1a7-b2d54db62dbb%2FUntitled.png?width=744&amp;table=block&amp;id=aee8b225-d04c-4c25-a109-27454946d3a6" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Keypoint estimation with Keypoint-RCNN-50</span></span></figcaption></figure></div><div id="https://www.notion.so/2d579b0adb4243338859a860fc46178b" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F81cb959e-db7b-4d89-95b9-eefb278888b0%2FUntitled.png?width=744&amp;table=block&amp;id=2d579b0a-db42-4333-8859-a860fc46178b"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F81cb959e-db7b-4d89-95b9-eefb278888b0%2FUntitled.png?width=744&amp;table=block&amp;id=2d579b0a-db42-4333-8859-a860fc46178b" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Panoptic segmentation with Panoptic-FPN-101</span></span></figcaption></figure></div><div id="https://www.notion.so/731c40f9f3b2409ca70f6f319f3920df" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc1ef51fb-f3d6-4871-9908-f6eb21167879%2FUntitled.png?width=744&amp;table=block&amp;id=731c40f9-f3b2-409c-a70f-6f319f3920df"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc1ef51fb-f3d6-4871-9908-f6eb21167879%2FUntitled.png?width=744&amp;table=block&amp;id=731c40f9-f3b2-409c-a70f-6f319f3920df" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Default Mask R-CNN (top) vs. Mask R-CNN with PointRend (bottom) comparison</span></span></figcaption></figure></div><div id="https://www.notion.so/b8a27fdffc70462a996dbe716e3e23cc" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/0f93c61942da41be983fae5bc939619c" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/0f93c61942da41be983fae5bc939619c"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Fine-tuning Balloons Dataset</span></span></h1><h3 id="https://www.notion.so/629e7b095e054128a43b7e46c9663096" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/629e7b095e054128a43b7e46c9663096"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Load the data</span></span></h3><pre id="https://www.notion.so/9bff42c91434439191a77d037a6f7869" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span># download, decompress the data
!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip
!unzip balloon_dataset.zip &gt; /dev/null</span></span></span></code></pre><h3 id="https://www.notion.so/ed19cba5206043b88230b7b9829d4e6c" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/ed19cba5206043b88230b7b9829d4e6c"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Convert dataset into Detectron2&#x27;s standard format</span></span></h3><pre id="https://www.notion.so/d16f2b8f5926433294eb5b737cde40b0" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>from detectron2.structures import BoxMode
# write a function that loads the dataset into detectron2&#x27;s standard format
def get_balloon_dicts(img_dir):
    json_file = os.path.join(img_dir, &quot;via_region_data.json&quot;)
    with open(json_file) as f:
        imgs_anns = json.load(f)

    dataset_dicts = []
    for _, v in imgs_anns.items():
        record = {}
        
        filename = os.path.join(img_dir, v[&quot;filename&quot;])
        height, width = cv2.imread(filename).shape[:2]
        
        record[&quot;file_name&quot;] = filename
        record[&quot;height&quot;] = height
        record[&quot;width&quot;] = width
      
        annos = v[&quot;regions&quot;]
        objs = []
        for _, anno in annos.items():
            assert not anno[&quot;region_attributes&quot;]
            anno = anno[&quot;shape_attributes&quot;]
            px = anno[&quot;all_points_x&quot;]
            py = anno[&quot;all_points_y&quot;]
            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]
            poly = list(itertools.chain.from_iterable(poly))

            obj = {
                &quot;bbox&quot;: [np.min(px), np.min(py), np.max(px), np.max(py)],
                &quot;bbox_mode&quot;: BoxMode.XYXY_ABS,
                &quot;segmentation&quot;: [poly],
                &quot;category_id&quot;: 0,
                &quot;iscrowd&quot;: 0
            }
            objs.append(obj)
        record[&quot;annotations&quot;] = objs
        dataset_dicts.append(record)
    return dataset_dicts

from detectron2.data import DatasetCatalog, MetadataCatalog
for d in [&quot;train&quot;, &quot;val&quot;]:
    DatasetCatalog.register(&quot;balloon/&quot; + d, lambda d=d: get_balloon_dicts(&quot;balloon/&quot; + d))
    MetadataCatalog.get(&quot;balloon/&quot; + d).set(thing_classes=[&quot;balloon&quot;])
balloon_metadata = MetadataCatalog.get(&quot;balloon/train&quot;)</span></span></span></code></pre><h3 id="https://www.notion.so/a98976a7c3ca4e98b520e93694646f8f" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/a98976a7c3ca4e98b520e93694646f8f"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Model configuration and training</span></span></h3><pre id="https://www.notion.so/68df810fe90a42c1bcf99422c2a46da4" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file(&quot;COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml&quot;))
cfg.DATASETS.TRAIN = (&quot;balloon/train&quot;,)
cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(&quot;COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml&quot;)
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.00025
cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough, but you can certainly train longer
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg) 
trainer.resume_or_load(resume=False)
trainer.train()</span></span></span></code></pre><h3 id="https://www.notion.so/b5ea96f14cec40938f6b67628e16658e" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/b5ea96f14cec40938f6b67628e16658e"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Inference and Visualization</span></span></h3><pre id="https://www.notion.so/9c8e6ff6d7e74f7d9b717170ae0a0aab" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>from detectron2.utils.visualizer import ColorMode

# load weights
cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, &quot;model_final.pth&quot;)
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model
# Set training data-set path
cfg.DATASETS.TEST = (&quot;balloon/val&quot;, )
# Create predictor (model for inference)
predictor = DefaultPredictor(cfg)

dataset_dicts = get_balloon_dicts(&quot;balloon/val&quot;)
for d in random.sample(dataset_dicts, 3):    
    im = cv2.imread(d[&quot;file_name&quot;])
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1],
                   metadata=balloon_metadata, 
                   scale=0.8, 
                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels
    )
    v = v.draw_instance_predictions(outputs[&quot;instances&quot;].to(&quot;cpu&quot;))
    cv2_imshow(v.get_image()[:, :, ::-1])</span></span></span></code></pre><div id="https://www.notion.so/e44fa30319c34e0aac52684e1737ad65" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/e467e4b7b94641d7a3a3f9d08482fe8a" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffdaa99ba-a091-40cc-836a-a444edcaa9a3%2FUntitled.png?width=819&amp;table=block&amp;id=e467e4b7-b946-41d7-a3a3-f9d08482fe8a"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffdaa99ba-a091-40cc-836a-a444edcaa9a3%2FUntitled.png?width=819&amp;table=block&amp;id=e467e4b7-b946-41d7-a3a3-f9d08482fe8a" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/7ee298565721444793fd9a395edab7bb" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3a614632-1a7e-4cd9-8892-a357567ad7de%2FUntitled.png?width=819&amp;table=block&amp;id=7ee29856-5721-4447-93fd-9a395edab7bb"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3a614632-1a7e-4cd9-8892-a357567ad7de%2FUntitled.png?width=819&amp;table=block&amp;id=7ee29856-5721-4447-93fd-9a395edab7bb" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/c4e1b2cfcb1f489aada2d4419e79eda4" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe64379ae-9003-4370-b2da-4db74fc0b681%2FUntitled.png?width=288&amp;table=block&amp;id=c4e1b2cf-cb1f-489a-ada2-d4419e79eda4"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe64379ae-9003-4370-b2da-4db74fc0b681%2FUntitled.png?width=288&amp;table=block&amp;id=c4e1b2cf-cb1f-489a-ada2-d4419e79eda4" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/61201bb6e72f40ceaab92a516830dbb0" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/8e6d5d32408e49ec9000465d177a5a11" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/8e6d5d32408e49ec9000465d177a5a11"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Fine-tuning Chip Dataset</span></span></h1><h3 id="https://www.notion.so/18e3ac4c5284406787360009737dbb92" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/18e3ac4c5284406787360009737dbb92"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Load the data</span></span></h3><pre id="https://www.notion.so/b245d4ac53864327bc8a3c4a8b2a9c4b" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>#get the dataset
!pip install -q kaggle
!pip install -q kaggle-cli
os.environ[&#x27;KAGGLE_USERNAME&#x27;] = &quot;sparshag&quot; 
os.environ[&#x27;KAGGLE_KEY&#x27;] = &quot;1b1f894d1fa6febe9676681b44ad807b&quot;
!kaggle datasets download -d tannergi/microcontroller-detection
!unzip microcontroller-detection.zip</span></span></span></code></pre><h3 id="https://www.notion.so/d4cf1aba93324c0a9550c4372cbd73bf" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/d4cf1aba93324c0a9550c4372cbd73bf"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Convert dataset into Detectron2&#x27;s standard format</span></span></h3><pre id="https://www.notion.so/f0b966570be4447e9765b1e208fe04a2" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span># Registering the dataset
from detectron2.structures import BoxMode
def get_microcontroller_dicts(csv_file, img_dir):
    df = pd.read_csv(csv_file)
    df[&#x27;filename&#x27;] = df[&#x27;filename&#x27;].map(lambda x: img_dir+x)

    classes = [&#x27;Raspberry_Pi_3&#x27;, &#x27;Arduino_Nano&#x27;, &#x27;ESP8266&#x27;, &#x27;Heltec_ESP32_Lora&#x27;]

    df[&#x27;class_int&#x27;] = df[&#x27;class&#x27;].map(lambda x: classes.index(x))

    dataset_dicts = []
    for filename in df[&#x27;filename&#x27;].unique().tolist():
        record = {}
        
        height, width = cv2.imread(filename).shape[:2]
        
        record[&quot;file_name&quot;] = filename
        record[&quot;height&quot;] = height
        record[&quot;width&quot;] = width

        objs = []
        for index, row in df[(df[&#x27;filename&#x27;]==filename)].iterrows():
          obj= {
              &#x27;bbox&#x27;: [row[&#x27;xmin&#x27;], row[&#x27;ymin&#x27;], row[&#x27;xmax&#x27;], row[&#x27;ymax&#x27;]],
              &#x27;bbox_mode&#x27;: BoxMode.XYXY_ABS,
              &#x27;category_id&#x27;: row[&#x27;class_int&#x27;],
              &quot;iscrowd&quot;: 0
          }
          objs.append(obj)
        record[&quot;annotations&quot;] = objs
        dataset_dicts.append(record)
    return dataset_dicts

classes = [&#x27;Raspberry_Pi_3&#x27;, &#x27;Arduino_Nano&#x27;, &#x27;ESP8266&#x27;, &#x27;Heltec_ESP32_Lora&#x27;]
for d in [&quot;train&quot;, &quot;test&quot;]:
  DatasetCatalog.register(&#x27;microcontroller/&#x27; + d, lambda d=d: get_microcontroller_dicts(&#x27;Microcontroller Detection/&#x27; + d + &#x27;_labels.csv&#x27;, &#x27;Microcontroller Detection/&#x27; + d+&#x27;/&#x27;))
  MetadataCatalog.get(&#x27;microcontroller/&#x27; + d).set(thing_classes=classes)
microcontroller_metadata = MetadataCatalog.get(&#x27;microcontroller/train&#x27;)</span></span></span></code></pre><h3 id="https://www.notion.so/eec1f17bbd1e4390a3824d1105b3ea31" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/eec1f17bbd1e4390a3824d1105b3ea31"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Model configuration and training</span></span></h3><pre id="https://www.notion.so/79b32995d55b46dcb4e3cfc8a68e3ece" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span># Train the model
cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file(&quot;COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml&quot;))
cfg.DATASETS.TRAIN = (&#x27;microcontroller/train&#x27;,)
cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(&quot;COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml&quot;)
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.MAX_ITER = 1000
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg) 
trainer.resume_or_load(resume=False)
trainer.train()</span></span></span></code></pre><div id="https://www.notion.so/5249c725af95406a86c31be5bb593692" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd0292a0d-0f24-48eb-a995-cbb63d92fff1%2FUntitled.png?width=765&amp;table=block&amp;id=5249c725-af95-406a-86c3-1be5bb593692"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd0292a0d-0f24-48eb-a995-cbb63d92fff1%2FUntitled.png?width=765&amp;table=block&amp;id=5249c725-af95-406a-86c3-1be5bb593692" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/d488c90e1abb48ce852a8b6ce1796d52" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F38d2b356-7d37-4a5e-9648-68f4d441b563%2FUntitled.png?width=640&amp;table=block&amp;id=d488c90e-1abb-48ce-852a-8b6ce1796d52"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F38d2b356-7d37-4a5e-9648-68f4d441b563%2FUntitled.png?width=640&amp;table=block&amp;id=d488c90e-1abb-48ce-852a-8b6ce1796d52" style="width:640px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><h3 id="https://www.notion.so/e1a75f4dc8814646b5d0e73c3c24df99" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/e1a75f4dc8814646b5d0e73c3c24df99"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Inference and Visualization</span></span></h3><pre id="https://www.notion.so/29eed4975c3842b09cf166f2b9d3458d" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, &quot;model_final.pth&quot;)
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model
cfg.DATASETS.TEST = (&#x27;microcontroller/test&#x27;, )
predictor = DefaultPredictor(cfg)

df_test = pd.read_csv(&#x27;Microcontroller Detection/test_labels.csv&#x27;)

dataset_dicts = DatasetCatalog.get(&#x27;microcontroller/test&#x27;)
for d in random.sample(dataset_dicts, 3):    
    im = cv2.imread(d[&quot;file_name&quot;])
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1], 
                   metadata=microcontroller_metadata, 
                   scale=0.8
                   )
    v = v.draw_instance_predictions(outputs[&quot;instances&quot;].to(&quot;cpu&quot;))
    cv2_imshow(v.get_image()[:, :, ::-1])</span></span></span></code></pre><h3 id="https://www.notion.so/a980b06799c442b88a6827cbdbdd8f69" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/a980b06799c442b88a6827cbdbdd8f69"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Real-time Webcam inference</span></span></h3><pre id="https://www.notion.so/c7ae84a50c7f45b1a2de18f0b7e1f9a8" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode

def take_photo(filename=&#x27;photo.jpg&#x27;, quality=0.8):
  js = Javascript(&#x27;&#x27;&#x27;
    async function takePhoto(quality) {
      const div = document.createElement(&#x27;div&#x27;);
      const capture = document.createElement(&#x27;button&#x27;);
      capture.textContent = &#x27;Capture&#x27;;
      div.appendChild(capture);

      const video = document.createElement(&#x27;video&#x27;);
      video.style.display = &#x27;block&#x27;;
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      // Wait for Capture to be clicked.
      await new Promise((resolve) =&gt; capture.onclick = resolve);

      const canvas = document.createElement(&#x27;canvas&#x27;);
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext(&#x27;2d&#x27;).drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL(&#x27;image/jpeg&#x27;, quality);
    }
    &#x27;&#x27;&#x27;)
  display(js)
  data = eval_js(&#x27;takePhoto({})&#x27;.format(quality))
  binary = b64decode(data.split(&#x27;,&#x27;)[1])
  with open(filename, &#x27;wb&#x27;) as f:
    f.write(binary)
  return filename

from IPython.display import Image
try:
  filename = take_photo()
  print(&#x27;Saved to {}&#x27;.format(filename))
  
  # Show the image which was just taken.
  display(Image(filename))
except Exception as err:
  # Errors will be thrown if the user does not have a webcam or if they do not
  # grant the page permission to access it.
  print(str(err))</span></span></span></code></pre><pre id="https://www.notion.so/ba72a1794a7d4a249a5c655164a7bc3d" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>model_path = &#x27;/content/output/model_final.pth&#x27;
config_path= model_zoo.get_config_file(&quot;COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml&quot;)

# Create config
cfg = get_cfg()
cfg.merge_from_file(config_path)
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1
cfg.MODEL.WEIGHTS = model_path

predictor = DefaultPredictor(cfg)

im = cv2.imread(&#x27;photo.jpg&#x27;)
outputs = predictor(im)

v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
v = v.draw_instance_predictions(outputs[&quot;instances&quot;].to(&quot;cpu&quot;))
cv2_imshow(v.get_image()[:, :, ::-1])</span></span></span></code></pre><div id="https://www.notion.so/a624fe9c1bd543bd9d76e164e0608891" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/b32aece5d69e47e9b60d7db06b15a1d9" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/b32aece5d69e47e9b60d7db06b15a1d9"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Fine-tuning on Face dataset</span></span></h1><div id="https://www.notion.so/777e37704d7b4f2bb5037e16fdea1285" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">The process is same. Here is the output.</span></span></p></div><div id="https://www.notion.so/1f3517c0a8194eadb91011239be7501d" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb2a4da68-0a9e-463f-bc21-badcb66a45c7%2FUntitled.png?width=1353&amp;table=block&amp;id=1f3517c0-a819-4ead-b910-11239be7501d"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb2a4da68-0a9e-463f-bc21-badcb66a45c7%2FUntitled.png?width=1353&amp;table=block&amp;id=1f3517c0-a819-4ead-b910-11239be7501d" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/85f077c9fd8c46568c45deb4bf9eacc1" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F04d64757-ab17-4184-ab46-a425bbe5e3fc%2FUntitled.png?width=700&amp;table=block&amp;id=85f077c9-fd8c-4656-8c45-deb4bf9eacc1"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F04d64757-ab17-4184-ab46-a425bbe5e3fc%2FUntitled.png?width=700&amp;table=block&amp;id=85f077c9-fd8c-4656-8c45-deb4bf9eacc1" style="width:700px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/f7a67107bd454344a10d61249243941a" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffbe20f92-daa1-4a15-8655-98583163da8c%2FUntitled.png?width=700&amp;table=block&amp;id=f7a67107-bd45-4344-a10d-61249243941a"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffbe20f92-daa1-4a15-8655-98583163da8c%2FUntitled.png?width=700&amp;table=block&amp;id=f7a67107-bd45-4344-a10d-61249243941a" style="width:700px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/1c0c5726ee264603a4d004c376de318a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/14811bd9a5f440138f9b6a28bb134ab9" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/14811bd9a5f440138f9b6a28bb134ab9"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Behind the scenes</span></span></h3><div id="https://www.notion.so/a414fe3355094d46a5e1841c3ee46620" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fcdbe7125-869d-4c2a-b51c-b7961018f192%2FUntitled.png?width=1071&amp;table=block&amp;id=a414fe33-5509-4d46-a5e1-841c3ee46620"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fcdbe7125-869d-4c2a-b51c-b7961018f192%2FUntitled.png?width=1071&amp;table=block&amp;id=a414fe33-5509-4d46-a5e1-841c3ee46620" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/28e86a35770d4811b9bc26c73ed06f5b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/8bb0981852fc4bb5ba8ff102c12d05b5" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/8bb0981852fc4bb5ba8ff102c12d05b5"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">References</span></span></h3><ul class="BulletedListWrapper"><li id="https://www.notion.so/e86f3fe565e048669ecd96e9a0a017f5" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://medium.com/deepvisionguru/how-to-embed-detectron2-in-your-computer-vision-project-817f29149461">How to embed Detectron2 in your computer vision project - blogpost</a></span></span></li><li id="https://www.notion.so/3ba86888741d43b8a6fe25e4b4f8f397" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://gilberttanner.com/blog/detectron2-train-a-instance-segmentation-model">Detectron2 Train a Instance Segmentation Model by Gilbert Tanner</a></span></span></li><li id="https://www.notion.so/7a568de97bda459fbc37b6ab03f2d4f4" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.dlology.com/blog/how-to-train-detectron2-with-custom-coco-datasets/">How to train Detectron2 with Custom COCO Datasets - DLology</a></span></span></li><li id="https://www.notion.so/359aa1547ec14fa78799713056c60da3" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://towardsdatascience.com/character-recognition-and-segmentation-for-custom-data-using-detectron2-599de82b393c">Character Recognition and Segmentation For Custom Data Using Detectron2 - blogpost</a></span></span></li><li id="https://www.notion.so/6f54e1ffaf4846dcbaf86f358f13c700" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.celantur.com/blog/panoptic-segmentation-in-detectron2/">Training models with Panoptic Segmentation in Detectron2</a></span></span></li><li id="https://www.notion.so/6941e27d259a43e48c6c2fc52ad276ac" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.kaggle.com/lewisgmorris/image-segmentation-using-detectron2">Image segmentation using Detectron2 - Kaggle</a></span></span></li><li id="https://www.notion.so/6aead586d2a542ceab16f64ca6b6314c" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://towardsdatascience.com/a-beginners-guide-to-object-detection-and-computer-vision-with-facebook-s-detectron2-700b6273390e">A Beginner’s Guide To Object Detection And Computer Vision With Facebook’s Detectron2</a></span></span></li><li id="https://www.notion.so/c96987263d8b450c9cdc7784dd0f08c6" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.curiousily.com/posts/face-detection-on-custom-dataset-with-detectron2-in-python/">Face Detection on Custom Dataset with Detectron2 and PyTorch using Python</a></span></span></li><li id="https://www.notion.so/70024c5431884898af2eda44f8f55c19" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.notion.so/knowledgetree/Detectron-2-d31ac9c14a8d4d9888882df14a4e0eee">My Experiment Notion</a></span></span></li><li id="https://www.notion.so/69fbe43abbde4ca2a853e1c0edb2a341" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5">Official Colab</a></span></span></li><li id="https://www.notion.so/0a15398a26c74d498b930ae2c8036bbe" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://research.fb.com/wp-content/uploads/2019/12/4.-detectron2.pdf">Official Slide</a></span></span></li><li id="https://www.notion.so/6d943736371e491f8b1138042301d297" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/facebookresearch/detectron2">Official Git</a></span></span></li></ul><div id="https://www.notion.so/1724b47f39b14a68ab5850f27364ad8e" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div></article>  <footer class="Footer">
        <div>&copy; Sparsh Agarwal 2021</div>
        <div>&centerdot;</div>
        <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
            rel="noopener noreferrer">Notablog</a>.
        </div>
    </footer>
</body>

</html>