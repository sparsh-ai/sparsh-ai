<!DOCTYPE html>
<html lang="en">

<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-5F9Y9HC95G"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5F9Y9HC95G');
</script>
<script data-ad-client="ca-pub-8325812071117232" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <!-- Chrome, Firefox OS and Opera Status Bar Color -->
  <meta name="theme-color" content="#FFFFFF">
  <meta property="og:title" content="Detectron 2">
    <meta property="og:type" content="blog">
  <title>Detectron 2</title>
<link rel="icon" href="⚡"/>
  <!-- Favicon -->
    <link rel="shortcut icon" target="_blank" href="⚡">
    <link rel="stylesheet" type="text/css" target="_blank" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
  <link rel="stylesheet" type="text/css"
    target="_blank" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
  <link rel="stylesheet" type="text/css" target="_blank" href="css/SourceSansPro.css">
  <link rel="stylesheet" type="text/css" target="_blank" href="css/notablog.css">
  <link rel="stylesheet" type="text/css" target="_blank" href="css/theme.css">
  <style>
    :root {
      font-size: 18px;
    }

    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
    <a href="index">
      <div class="Navbar__Btn"><span>⚡</span> <span>Home</span></div>
    </a>
                                                                                                                                                    <span class="Navbar__Delim">&centerdot;</span>
    <a href="large-projects">
      <div class="Navbar__Btn"><span><img class="inline-img-icon" src="https://super.so/icon/dark/server.svg"></span> <span>Projects</span></div>
    </a>
                <span class="Navbar__Delim">&centerdot;</span>
    <a href="notes">
      <div class="Navbar__Btn"><span><img class="inline-img-icon" src="https://super.so/icon/dark/folder.svg"></span> <span>Notes</span></div>
    </a>
                <span class="Navbar__Delim">&centerdot;</span>
    <a href="apps">
      <div class="Navbar__Btn"><span><img class="inline-img-icon" src="https://super.so/icon/dark/droplet.svg"></span> <span>Apps</span></div>
    </a>
                <span class="Navbar__Delim">&centerdot;</span>
    <a href="jupyter-notebooks">
      <div class="Navbar__Btn"><span><img class="inline-img-icon" src="https://super.so/icon/dark/book.svg"></span> <span>Jupyter</span></div>
    </a>
                <span class="Navbar__Delim">&centerdot;</span>
    <a href="about">
      <div class="Navbar__Btn"><span><img class="inline-img-icon" src="https://super.so/icon/dark/send.svg"></span> <span>About</span></div>
    </a>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </nav>
  <header class="Header">
          <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
        <h1 class="Header__Title">Detectron 2</h1>
            <div class="DateTagBar">
                <span class="DateTagBar__Item DateTagBar__Date">Posted on Mon, Jan 4, 2021</span>
                            </div>
          </header>
      <article id="https://www.notion.so/6828b78166e54b8fba9b10081f18b455" class="PageRoot"><div id="https://www.notion.so/c7dd0125364c489e83804159d5532c2f" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3d5bb330-275c-4a02-854b-6a38d15090b8%2FUntitled.png?width=1347&amp;table=block&amp;id=c7dd0125-364c-489e-8380-4159d5532c2f"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3d5bb330-275c-4a02-854b-6a38d15090b8%2FUntitled.png?width=1347&amp;table=block&amp;id=c7dd0125-364c-489e-8380-4159d5532c2f" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><h1 id="https://www.notion.so/e13a0705378f4ddf99e50f61bab03f17" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" target="_blank" href="#https://www.notion.so/e13a0705378f4ddf99e50f61bab03f17"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Introduction</span></span></h1><div id="https://www.notion.so/51bef69589494959a31578d381bf48c2" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Detectron 2 is a next-generation open-source object detection system from Facebook AI Research. With the repo you can use and train the various state-of-the-art models for detection tasks such as bounding-box detection, instance and semantic segmentation, and person keypoint detection.</span></span></p></div><div id="https://www.notion.so/b2093a3efba64c119dc09af5d85b41c0" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">The following is the directory tree of detectron 2:</span></span></p></div><pre id="https://www.notion.so/b60081afec1c45f3b2c9fc055a578489" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>detectron2
├─checkpoint  &lt;- checkpointer and model catalog handlers
├─config      &lt;- default configs and handlers
├─data        &lt;- dataset handlers and data loaders
├─engine      &lt;- predictor and trainer engines
├─evaluation  &lt;- evaluator for each dataset
├─export      &lt;- converter of detectron2 models to caffe2 (ONNX)
├─layers      &lt;- custom layers e.g. deformable conv.
├─model_zoo   &lt;- pre-trained model links and handler
├─modeling   
│  ├─meta_arch &lt;- meta architecture e.g. R-CNN, RetinaNet
│  ├─backbone  &lt;- backbone network e.g. ResNet, FPN
│  ├─proposal_generator &lt;- region proposal network
│  └─roi_heads &lt;- head networks for pooled ROIs e.g. box, mask heads
├─solver       &lt;- optimizer and scheduler builders
├─structures   &lt;- structure classes e.g. Boxes, Instances, etc
└─utils        &lt;- utility modules e.g. visualizer, logger, etc</span></span></span></code></pre><h1 id="https://www.notion.so/ed4c32a90c7348d8a7cebe15e9615e89" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" target="_blank" href="#https://www.notion.so/ed4c32a90c7348d8a7cebe15e9615e89"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Installation</span></span></h1><pre id="https://www.notion.so/a0487148ce9d473abd621b8c19bf5327" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span><span class="token operator">%</span><span class="token operator">%</span>time
!pip install <span class="token operator">-</span>U torch<span class="token operator">==</span><span class="token number">1.4</span><span class="token operator">+</span>cu100 torchvision<span class="token operator">==</span><span class="token number">0.5</span><span class="token operator">+</span>cu100 <span class="token operator">-</span>f https<span class="token punctuation">:</span><span class="token operator">//</span>download<span class="token punctuation">.</span>pytorch<span class="token punctuation">.</span>org<span class="token operator">/</span>whl<span class="token operator">/</span>torch_stable<span class="token punctuation">.</span>html<span class="token punctuation">;</span>
!pip install cython pyyaml<span class="token operator">==</span><span class="token number">5.1</span><span class="token punctuation">;</span>
!pip install <span class="token operator">-</span>U <span class="token string">'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'</span><span class="token punctuation">;</span>
!pip install detectron2 <span class="token operator">-</span>f https<span class="token punctuation">:</span><span class="token operator">//</span>dl<span class="token punctuation">.</span>fbaipublicfiles<span class="token punctuation">.</span>com<span class="token operator">/</span>detectron2<span class="token operator">/</span>wheels<span class="token operator">/</span>cu100<span class="token operator">/</span>index<span class="token punctuation">.</span>html<span class="token punctuation">;</span>

<span class="token keyword">from</span> detectron2 <span class="token keyword">import</span> model_zoo
<span class="token keyword">from</span> detectron2<span class="token punctuation">.</span>engine <span class="token keyword">import</span> DefaultPredictor
<span class="token keyword">from</span> detectron2<span class="token punctuation">.</span>config <span class="token keyword">import</span> get_cfg
<span class="token keyword">from</span> detectron2<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>visualizer <span class="token keyword">import</span> Visualizer
<span class="token keyword">from</span> detectron2<span class="token punctuation">.</span>data <span class="token keyword">import</span> MetadataCatalog</span></span></span></code></pre><h1 id="https://www.notion.so/fcc0f63b96644dbebe2202856be2e4d3" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" target="_blank" href="#https://www.notion.so/fcc0f63b96644dbebe2202856be2e4d3"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Inference on pre-trained models</span></span></h1><div id="https://www.notion.so/55267ac2190341a48006aacd793a2ba7" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffeaf135e-a211-420b-8cdb-24dc6cc932e5%2FUntitled.png?width=672&amp;table=block&amp;id=55267ac2-1903-41a4-8006-aacd793a2ba7"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffeaf135e-a211-420b-8cdb-24dc6cc932e5%2FUntitled.png?width=672&amp;table=block&amp;id=55267ac2-1903-41a4-8006-aacd793a2ba7" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Original image</span></span></figcaption></figure></div><div id="https://www.notion.so/6c65aaefcde1490f8d87232f5a26e524" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F23f21d25-a97b-44b3-b45e-17f69b5385b5%2FUntitled.png?width=744&amp;table=block&amp;id=6c65aaef-cde1-490f-8d87-232f5a26e524"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F23f21d25-a97b-44b3-b45e-17f69b5385b5%2FUntitled.png?width=744&amp;table=block&amp;id=6c65aaef-cde1-490f-8d87-232f5a26e524" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Object detection with Faster-RCNN-101</span></span></figcaption></figure></div><div id="https://www.notion.so/d3d982b6a1ca47f0ae8f2bbbe4cf49b0" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F345be1d0-0c2f-4084-be4b-02c22422b930%2FUntitled.png?width=744&amp;table=block&amp;id=d3d982b6-a1ca-47f0-ae8f-2bbbe4cf49b0"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F345be1d0-0c2f-4084-be4b-02c22422b930%2FUntitled.png?width=744&amp;table=block&amp;id=d3d982b6-a1ca-47f0-ae8f-2bbbe4cf49b0" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Instance segmentation with Mask-RCNN-50</span></span></figcaption></figure></div><div id="https://www.notion.so/10540e78fe814ecd9fd4b5e0aa0f943c" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/37b6929aa8704a2bb6f013ce6ed6b359" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F19c46bd9-c2fb-4999-a1a7-b2d54db62dbb%2FUntitled.png?width=744&amp;table=block&amp;id=37b6929a-a870-4a2b-b6f0-13ce6ed6b359"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F19c46bd9-c2fb-4999-a1a7-b2d54db62dbb%2FUntitled.png?width=744&amp;table=block&amp;id=37b6929a-a870-4a2b-b6f0-13ce6ed6b359" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Keypoint estimation with Keypoint-RCNN-50</span></span></figcaption></figure></div><div id="https://www.notion.so/1da1e1f818534336b22eedf21fc8ac38" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F81cb959e-db7b-4d89-95b9-eefb278888b0%2FUntitled.png?width=744&amp;table=block&amp;id=1da1e1f8-1853-4336-b22e-edf21fc8ac38"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F81cb959e-db7b-4d89-95b9-eefb278888b0%2FUntitled.png?width=744&amp;table=block&amp;id=1da1e1f8-1853-4336-b22e-edf21fc8ac38" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Panoptic segmentation with Panoptic-FPN-101</span></span></figcaption></figure></div><div id="https://www.notion.so/7126577129374452aa6ca19f235fbd00" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc1ef51fb-f3d6-4871-9908-f6eb21167879%2FUntitled.png?width=744&amp;table=block&amp;id=71265771-2937-4452-aa6c-a19f235fbd00"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc1ef51fb-f3d6-4871-9908-f6eb21167879%2FUntitled.png?width=744&amp;table=block&amp;id=71265771-2937-4452-aa6c-a19f235fbd00" style="width:100%"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Default Mask R-CNN (top) vs. Mask R-CNN with PointRend (bottom) comparison</span></span></figcaption></figure></div><div id="https://www.notion.so/cf54238bf806460eb671bee0df44c01e" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/0981e3b55a034b879ccc997f053c507f" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" target="_blank" href="#https://www.notion.so/0981e3b55a034b879ccc997f053c507f"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Fine-tuning Balloons Dataset</span></span></h1><h3 id="https://www.notion.so/ea94a39462a24cc1a30b9f4c71faaf81" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" target="_blank" href="#https://www.notion.so/ea94a39462a24cc1a30b9f4c71faaf81"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Load the data</span></span></h3><pre id="https://www.notion.so/23d07c546d154e0697e14f9181cbe4e1" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span># download, decompress the data
!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip
!unzip balloon_dataset.zip &gt; /dev/null</span></span></span></code></pre><h3 id="https://www.notion.so/e1510f8871094bac943eea028547b6c6" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" target="_blank" href="#https://www.notion.so/e1510f8871094bac943eea028547b6c6"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Convert dataset into Detectron2&#x27;s standard format</span></span></h3><pre id="https://www.notion.so/ef954dc3b47645ab8cef9b3dae89334b" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>from detectron2.structures import BoxMode
# write a function that loads the dataset into detectron2&#x27;s standard format
def get_balloon_dicts(img_dir):
    json_file = os.path.join(img_dir, &quot;via_region_data.json&quot;)
    with open(json_file) as f:
        imgs_anns = json.load(f)

    dataset_dicts = []
    for _, v in imgs_anns.items():
        record = {}
        
        filename = os.path.join(img_dir, v[&quot;filename&quot;])
        height, width = cv2.imread(filename).shape[:2]
        
        record[&quot;file_name&quot;] = filename
        record[&quot;height&quot;] = height
        record[&quot;width&quot;] = width
      
        annos = v[&quot;regions&quot;]
        objs = []
        for _, anno in annos.items():
            assert not anno[&quot;region_attributes&quot;]
            anno = anno[&quot;shape_attributes&quot;]
            px = anno[&quot;all_points_x&quot;]
            py = anno[&quot;all_points_y&quot;]
            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]
            poly = list(itertools.chain.from_iterable(poly))

            obj = {
                &quot;bbox&quot;: [np.min(px), np.min(py), np.max(px), np.max(py)],
                &quot;bbox_mode&quot;: BoxMode.XYXY_ABS,
                &quot;segmentation&quot;: [poly],
                &quot;category_id&quot;: 0,
                &quot;iscrowd&quot;: 0
            }
            objs.append(obj)
        record[&quot;annotations&quot;] = objs
        dataset_dicts.append(record)
    return dataset_dicts

from detectron2.data import DatasetCatalog, MetadataCatalog
for d in [&quot;train&quot;, &quot;val&quot;]:
    DatasetCatalog.register(&quot;balloon/&quot; + d, lambda d=d: get_balloon_dicts(&quot;balloon/&quot; + d))
    MetadataCatalog.get(&quot;balloon/&quot; + d).set(thing_classes=[&quot;balloon&quot;])
balloon_metadata = MetadataCatalog.get(&quot;balloon/train&quot;)</span></span></span></code></pre><h3 id="https://www.notion.so/5767224c0c724666be506a898b918702" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" target="_blank" href="#https://www.notion.so/5767224c0c724666be506a898b918702"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Model configuration and training</span></span></h3><pre id="https://www.notion.so/acb24c8d89ee4d9ca903055121f91a56" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file(&quot;COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml&quot;))
cfg.DATASETS.TRAIN = (&quot;balloon/train&quot;,)
cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(&quot;COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml&quot;)
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.00025
cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough, but you can certainly train longer
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg) 
trainer.resume_or_load(resume=False)
trainer.train()</span></span></span></code></pre><h3 id="https://www.notion.so/d3a7c2aab87e488b8cdb9053187e9312" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" target="_blank" href="#https://www.notion.so/d3a7c2aab87e488b8cdb9053187e9312"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Inference and Visualization</span></span></h3><pre id="https://www.notion.so/1a4601db677c4e06ba33f037e2aba548" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>from detectron2.utils.visualizer import ColorMode

# load weights
cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, &quot;model_final.pth&quot;)
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model
# Set training data-set path
cfg.DATASETS.TEST = (&quot;balloon/val&quot;, )
# Create predictor (model for inference)
predictor = DefaultPredictor(cfg)

dataset_dicts = get_balloon_dicts(&quot;balloon/val&quot;)
for d in random.sample(dataset_dicts, 3):    
    im = cv2.imread(d[&quot;file_name&quot;])
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1],
                   metadata=balloon_metadata, 
                   scale=0.8, 
                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels
    )
    v = v.draw_instance_predictions(outputs[&quot;instances&quot;].to(&quot;cpu&quot;))
    cv2_imshow(v.get_image()[:, :, ::-1])</span></span></span></code></pre><div id="https://www.notion.so/510282d088f4475791f6dbb75bf4abe6" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/a7a7f21bdefd4d3e80c8bb34418805ce" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffdaa99ba-a091-40cc-836a-a444edcaa9a3%2FUntitled.png?width=819&amp;table=block&amp;id=a7a7f21b-defd-4d3e-80c8-bb34418805ce"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffdaa99ba-a091-40cc-836a-a444edcaa9a3%2FUntitled.png?width=819&amp;table=block&amp;id=a7a7f21b-defd-4d3e-80c8-bb34418805ce" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/4b8fc367fea44110bc7cbd59422c2b46" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3a614632-1a7e-4cd9-8892-a357567ad7de%2FUntitled.png?width=819&amp;table=block&amp;id=4b8fc367-fea4-4110-bc7c-bd59422c2b46"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3a614632-1a7e-4cd9-8892-a357567ad7de%2FUntitled.png?width=819&amp;table=block&amp;id=4b8fc367-fea4-4110-bc7c-bd59422c2b46" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/d810a97c104c4cbaa0fb0b9283597b6e" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe64379ae-9003-4370-b2da-4db74fc0b681%2FUntitled.png?width=288&amp;table=block&amp;id=d810a97c-104c-4cba-a0fb-0b9283597b6e"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe64379ae-9003-4370-b2da-4db74fc0b681%2FUntitled.png?width=288&amp;table=block&amp;id=d810a97c-104c-4cba-a0fb-0b9283597b6e" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/0d5c1ea1d1e34613ad3eb660a808b96b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/fa8874787fe64939b40465f374f9b6f4" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" target="_blank" href="#https://www.notion.so/fa8874787fe64939b40465f374f9b6f4"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Fine-tuning Chip Dataset</span></span></h1><h3 id="https://www.notion.so/d67fc002c738404a9020ae292b58efab" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" target="_blank" href="#https://www.notion.so/d67fc002c738404a9020ae292b58efab"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Load the data</span></span></h3><pre id="https://www.notion.so/076357737681411288b6306c09e92796" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>#get the dataset
!pip install -q kaggle
!pip install -q kaggle-cli
os.environ[&#x27;KAGGLE_USERNAME&#x27;] = &quot;sparshag&quot; 
os.environ[&#x27;KAGGLE_KEY&#x27;] = &quot;1b1f894d1fa6febe9676681b44ad807b&quot;
!kaggle datasets download -d tannergi/microcontroller-detection
!unzip microcontroller-detection.zip</span></span></span></code></pre><h3 id="https://www.notion.so/52400607ecfb4b04884214c0ab72d19a" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" target="_blank" href="#https://www.notion.so/52400607ecfb4b04884214c0ab72d19a"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Convert dataset into Detectron2&#x27;s standard format</span></span></h3><pre id="https://www.notion.so/69ef634d33a74eba98f3f67c1519d80e" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span># Registering the dataset
from detectron2.structures import BoxMode
def get_microcontroller_dicts(csv_file, img_dir):
    df = pd.read_csv(csv_file)
    df[&#x27;filename&#x27;] = df[&#x27;filename&#x27;].map(lambda x: img_dir+x)

    classes = [&#x27;Raspberry_Pi_3&#x27;, &#x27;Arduino_Nano&#x27;, &#x27;ESP8266&#x27;, &#x27;Heltec_ESP32_Lora&#x27;]

    df[&#x27;class_int&#x27;] = df[&#x27;class&#x27;].map(lambda x: classes.index(x))

    dataset_dicts = []
    for filename in df[&#x27;filename&#x27;].unique().tolist():
        record = {}
        
        height, width = cv2.imread(filename).shape[:2]
        
        record[&quot;file_name&quot;] = filename
        record[&quot;height&quot;] = height
        record[&quot;width&quot;] = width

        objs = []
        for index, row in df[(df[&#x27;filename&#x27;]==filename)].iterrows():
          obj= {
              &#x27;bbox&#x27;: [row[&#x27;xmin&#x27;], row[&#x27;ymin&#x27;], row[&#x27;xmax&#x27;], row[&#x27;ymax&#x27;]],
              &#x27;bbox_mode&#x27;: BoxMode.XYXY_ABS,
              &#x27;category_id&#x27;: row[&#x27;class_int&#x27;],
              &quot;iscrowd&quot;: 0
          }
          objs.append(obj)
        record[&quot;annotations&quot;] = objs
        dataset_dicts.append(record)
    return dataset_dicts

classes = [&#x27;Raspberry_Pi_3&#x27;, &#x27;Arduino_Nano&#x27;, &#x27;ESP8266&#x27;, &#x27;Heltec_ESP32_Lora&#x27;]
for d in [&quot;train&quot;, &quot;test&quot;]:
  DatasetCatalog.register(&#x27;microcontroller/&#x27; + d, lambda d=d: get_microcontroller_dicts(&#x27;Microcontroller Detection/&#x27; + d + &#x27;_labels.csv&#x27;, &#x27;Microcontroller Detection/&#x27; + d+&#x27;/&#x27;))
  MetadataCatalog.get(&#x27;microcontroller/&#x27; + d).set(thing_classes=classes)
microcontroller_metadata = MetadataCatalog.get(&#x27;microcontroller/train&#x27;)</span></span></span></code></pre><h3 id="https://www.notion.so/13a1df4e261b4995891a47faeb147f93" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" target="_blank" href="#https://www.notion.so/13a1df4e261b4995891a47faeb147f93"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Model configuration and training</span></span></h3><pre id="https://www.notion.so/91092d9b870042aa8affe2cb1fd862c0" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span># Train the model
cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file(&quot;COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml&quot;))
cfg.DATASETS.TRAIN = (&#x27;microcontroller/train&#x27;,)
cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(&quot;COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml&quot;)
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.MAX_ITER = 1000
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg) 
trainer.resume_or_load(resume=False)
trainer.train()</span></span></span></code></pre><div id="https://www.notion.so/c13e8f099ef0467196a2126f4dbe4282" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd0292a0d-0f24-48eb-a995-cbb63d92fff1%2FUntitled.png?width=765&amp;table=block&amp;id=c13e8f09-9ef0-4671-96a2-126f4dbe4282"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd0292a0d-0f24-48eb-a995-cbb63d92fff1%2FUntitled.png?width=765&amp;table=block&amp;id=c13e8f09-9ef0-4671-96a2-126f4dbe4282" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/d8ce7045360544c8a12e1c1e044b4eab" class="Image Image--Normal"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F38d2b356-7d37-4a5e-9648-68f4d441b563%2FUntitled.png?width=640&amp;table=block&amp;id=d8ce7045-3605-44c8-a12e-1c1e044b4eab"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F38d2b356-7d37-4a5e-9648-68f4d441b563%2FUntitled.png?width=640&amp;table=block&amp;id=d8ce7045-3605-44c8-a12e-1c1e044b4eab" style="width:640px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><h3 id="https://www.notion.so/52e2fb1f746b428ebc6041756c786bcd" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" target="_blank" href="#https://www.notion.so/52e2fb1f746b428ebc6041756c786bcd"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Inference and Visualization</span></span></h3><pre id="https://www.notion.so/fdc7e592d3af4f6baa6b3609d28da8d4" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, &quot;model_final.pth&quot;)
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model
cfg.DATASETS.TEST = (&#x27;microcontroller/test&#x27;, )
predictor = DefaultPredictor(cfg)

df_test = pd.read_csv(&#x27;Microcontroller Detection/test_labels.csv&#x27;)

dataset_dicts = DatasetCatalog.get(&#x27;microcontroller/test&#x27;)
for d in random.sample(dataset_dicts, 3):    
    im = cv2.imread(d[&quot;file_name&quot;])
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1], 
                   metadata=microcontroller_metadata, 
                   scale=0.8
                   )
    v = v.draw_instance_predictions(outputs[&quot;instances&quot;].to(&quot;cpu&quot;))
    cv2_imshow(v.get_image()[:, :, ::-1])</span></span></span></code></pre><h3 id="https://www.notion.so/1d390d7c19ef4579bb926fad172c9d10" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" target="_blank" href="#https://www.notion.so/1d390d7c19ef4579bb926fad172c9d10"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Real-time Webcam inference</span></span></h3><pre id="https://www.notion.so/a2c9ac04810c43c392ee4656fa9f4c93" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode

def take_photo(filename=&#x27;photo.jpg&#x27;, quality=0.8):
  js = Javascript(&#x27;&#x27;&#x27;
    async function takePhoto(quality) {
      const div = document.createElement(&#x27;div&#x27;);
      const capture = document.createElement(&#x27;button&#x27;);
      capture.textContent = &#x27;Capture&#x27;;
      div.appendChild(capture);

      const video = document.createElement(&#x27;video&#x27;);
      video.style.display = &#x27;block&#x27;;
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      // Wait for Capture to be clicked.
      await new Promise((resolve) =&gt; capture.onclick = resolve);

      const canvas = document.createElement(&#x27;canvas&#x27;);
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext(&#x27;2d&#x27;).drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL(&#x27;image/jpeg&#x27;, quality);
    }
    &#x27;&#x27;&#x27;)
  display(js)
  data = eval_js(&#x27;takePhoto({})&#x27;.format(quality))
  binary = b64decode(data.split(&#x27;,&#x27;)[1])
  with open(filename, &#x27;wb&#x27;) as f:
    f.write(binary)
  return filename

from IPython.display import Image
try:
  filename = take_photo()
  print(&#x27;Saved to {}&#x27;.format(filename))
  
  # Show the image which was just taken.
  display(Image(filename))
except Exception as err:
  # Errors will be thrown if the user does not have a webcam or if they do not
  # grant the page permission to access it.
  print(str(err))</span></span></span></code></pre><pre id="https://www.notion.so/478fda40418941dc913b9bbfc90c9561" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span>model_path = &#x27;/content/output/model_final.pth&#x27;
config_path= model_zoo.get_config_file(&quot;COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml&quot;)

# Create config
cfg = get_cfg()
cfg.merge_from_file(config_path)
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1
cfg.MODEL.WEIGHTS = model_path

predictor = DefaultPredictor(cfg)

im = cv2.imread(&#x27;photo.jpg&#x27;)
outputs = predictor(im)

v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
v = v.draw_instance_predictions(outputs[&quot;instances&quot;].to(&quot;cpu&quot;))
cv2_imshow(v.get_image()[:, :, ::-1])</span></span></span></code></pre><div id="https://www.notion.so/f7e85756ebf8462c911957aa00377ec2" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/f47091f1f36d4871a2c73f04c1bc81ef" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" target="_blank" href="#https://www.notion.so/f47091f1f36d4871a2c73f04c1bc81ef"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Fine-tuning on Face dataset</span></span></h1><div id="https://www.notion.so/7812f268c52845e4a8afeaf091aed3b8" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">The process is same. Here is the output.</span></span></p></div><div id="https://www.notion.so/e0e92b40b50342df8e6abb0aaf31b734" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb2a4da68-0a9e-463f-bc21-badcb66a45c7%2FUntitled.png?width=1353&amp;table=block&amp;id=e0e92b40-b503-42df-8e6a-bb0aaf31b734"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb2a4da68-0a9e-463f-bc21-badcb66a45c7%2FUntitled.png?width=1353&amp;table=block&amp;id=e0e92b40-b503-42df-8e6a-bb0aaf31b734" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/8fc8a3b1e30c4097ba0bd59e55f55ae9" class="Image Image--Normal"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F04d64757-ab17-4184-ab46-a425bbe5e3fc%2FUntitled.png?width=700&amp;table=block&amp;id=8fc8a3b1-e30c-4097-ba0b-d59e55f55ae9"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F04d64757-ab17-4184-ab46-a425bbe5e3fc%2FUntitled.png?width=700&amp;table=block&amp;id=8fc8a3b1-e30c-4097-ba0b-d59e55f55ae9" style="width:700px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/7255aeec8dc64634becfac31f4ac8992" class="Image Image--Normal"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffbe20f92-daa1-4a15-8655-98583163da8c%2FUntitled.png?width=700&amp;table=block&amp;id=7255aeec-8dc6-4634-becf-ac31f4ac8992"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffbe20f92-daa1-4a15-8655-98583163da8c%2FUntitled.png?width=700&amp;table=block&amp;id=7255aeec-8dc6-4634-becf-ac31f4ac8992" style="width:700px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/8bbca560ea394f84b4fd33ec3d9bc616" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/1df40e847205470bbbe2bb80cff3f074" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" target="_blank" href="#https://www.notion.so/1df40e847205470bbbe2bb80cff3f074"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Behind the scenes</span></span></h3><div id="https://www.notion.so/4fb602a0a14b4843b5cc9fe759578284" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fcdbe7125-869d-4c2a-b51c-b7961018f192%2FUntitled.png?width=1071&amp;table=block&amp;id=4fb602a0-a14b-4843-b5cc-9fe759578284"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fcdbe7125-869d-4c2a-b51c-b7961018f192%2FUntitled.png?width=1071&amp;table=block&amp;id=4fb602a0-a14b-4843-b5cc-9fe759578284" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/1ff925235e404008b47e4cc5b796aac4" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/76a475f5250445d586dced882c49eb18" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" target="_blank" href="#https://www.notion.so/76a475f5250445d586dced882c49eb18"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">References</span></span></h3><ul class="BulletedListWrapper"><li id="https://www.notion.so/22aeb0b17b084135b17680a38475939e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://medium.com/deepvisionguru/how-to-embed-detectron2-in-your-computer-vision-project-817f29149461">How to embed Detectron2 in your computer vision project - blogpost</a></span></span></li><li id="https://www.notion.so/4e4cf39282f44f3cbe6911c0305362ad" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://gilberttanner.com/blog/detectron2-train-a-instance-segmentation-model">Detectron2 Train a Instance Segmentation Model by Gilbert Tanner</a></span></span></li><li id="https://www.notion.so/39b78451abb64c68ab57e69a164f5444" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://www.dlology.com/blog/how-to-train-detectron2-with-custom-coco-datasets/">How to train Detectron2 with Custom COCO Datasets - DLology</a></span></span></li><li id="https://www.notion.so/14aceda43f3a4811a64b37bbdbc301c7" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://towardsdatascience.com/character-recognition-and-segmentation-for-custom-data-using-detectron2-599de82b393c">Character Recognition and Segmentation For Custom Data Using Detectron2 - blogpost</a></span></span></li><li id="https://www.notion.so/e1c941b89075480ea64a162fdff0fa91" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://www.celantur.com/blog/panoptic-segmentation-in-detectron2/">Training models with Panoptic Segmentation in Detectron2</a></span></span></li><li id="https://www.notion.so/db80371534514db68bb82da91a387d11" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://www.kaggle.com/lewisgmorris/image-segmentation-using-detectron2">Image segmentation using Detectron2 - Kaggle</a></span></span></li><li id="https://www.notion.so/7bd2292f94204a37b3f7323261a2b642" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://towardsdatascience.com/a-beginners-guide-to-object-detection-and-computer-vision-with-facebook-s-detectron2-700b6273390e">A Beginner’s Guide To Object Detection And Computer Vision With Facebook’s Detectron2</a></span></span></li><li id="https://www.notion.so/7a8cf004fe364d6ebd1f7a236cfce441" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://www.curiousily.com/posts/face-detection-on-custom-dataset-with-detectron2-in-python/">Face Detection on Custom Dataset with Detectron2 and PyTorch using Python</a></span></span></li><li id="https://www.notion.so/bcb59447759a4651af601e964913f964" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://www.notion.so/knowledgetree/Detectron-2-d31ac9c14a8d4d9888882df14a4e0eee">My Experiment Notion</a></span></span></li><li id="https://www.notion.so/8673730339194404ae0baa35456f4802" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5">Official Colab</a></span></span></li><li id="https://www.notion.so/d02114d12a6243bf8f0c80ded6d00bff" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://research.fb.com/wp-content/uploads/2019/12/4.-detectron2.pdf">Official Slide</a></span></span></li><li id="https://www.notion.so/4eb01535d2ef4d669c4ceb4c7a7a609a" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://github.com/facebookresearch/detectron2">Official Git</a></span></span></li></ul><div id="https://www.notion.so/10c78e15eb824b578dabb1e6a3ea55d2" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div></article>  <footer class="Footer">
        <div>&copy; Sparsh Agarwal 2021</div>
        <div>&centerdot;</div>
        <div>Powered by <a target="_blank" href="https://github.com/dragonman225/notablog" target="_blank"
            rel="noopener noreferrer">Notablog</a>.
        </div>
    </footer>
</body>

</html>